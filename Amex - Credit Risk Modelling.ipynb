{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eVoujL1w0tp"
      },
      "source": [
        "# MS4610 Introduction to Data Analytics Final Project\n",
        "\n",
        "# Amex Classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUcM5E2MxNFX"
      },
      "source": [
        "## (A) Importing the datasets and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBfXMwfSxNFX",
        "outputId": "7e23928d-1723-4af7-9977-e6db5302b6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFHBTa8v7Miz",
        "outputId": "8f24e2d4-eea8-4cf2-a060-5ef8fd4a8b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.27)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.6)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.4.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.3.3)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou2iK_WOxNFZ"
      },
      "outputs": [],
      "source": [
        "# Data Visualization Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ML Models\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Machine Learning Preprocessing Libraries\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Stastical analysis libraries\n",
        "from scipy.stats import probplot, chisquare\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from lightgbm import LGBMClassifier\n",
        "from scipy.stats import skew\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# For hyperparamater tuning\n",
        "import optuna\n",
        "\n",
        "# Path to datasets\n",
        "train_path = \"/content/drive/MyDrive/IDA Group Project/Project Details/Training Data_2021.csv\"\n",
        "test_path = \"/content/drive/MyDrive/IDA Group Project/Project Details/Test Data_2021.csv\"\n",
        "\n",
        "# Importing the datasets\n",
        "train_data = pd.read_csv(train_path, low_memory=False)    # low_memory = False is to ensure that there are no mixed data types\n",
        "test_data = pd.read_csv(test_path, low_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roe5OIS5xNFa",
        "outputId": "9f89cdc7-02de-463c-c868-d6cca36ab6e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(83000, 49)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_key</th>\n",
              "      <th>mvar1</th>\n",
              "      <th>mvar2</th>\n",
              "      <th>mvar3</th>\n",
              "      <th>mvar4</th>\n",
              "      <th>mvar5</th>\n",
              "      <th>mvar6</th>\n",
              "      <th>mvar7</th>\n",
              "      <th>mvar8</th>\n",
              "      <th>mvar9</th>\n",
              "      <th>mvar10</th>\n",
              "      <th>mvar11</th>\n",
              "      <th>mvar12</th>\n",
              "      <th>mvar13</th>\n",
              "      <th>mvar14</th>\n",
              "      <th>mvar15</th>\n",
              "      <th>mvar16</th>\n",
              "      <th>mvar17</th>\n",
              "      <th>mvar18</th>\n",
              "      <th>mvar19</th>\n",
              "      <th>mvar20</th>\n",
              "      <th>mvar21</th>\n",
              "      <th>mvar22</th>\n",
              "      <th>mvar23</th>\n",
              "      <th>mvar24</th>\n",
              "      <th>mvar25</th>\n",
              "      <th>mvar26</th>\n",
              "      <th>mvar27</th>\n",
              "      <th>mvar28</th>\n",
              "      <th>mvar29</th>\n",
              "      <th>mvar30</th>\n",
              "      <th>mvar31</th>\n",
              "      <th>mvar32</th>\n",
              "      <th>mvar33</th>\n",
              "      <th>mvar34</th>\n",
              "      <th>mvar35</th>\n",
              "      <th>mvar36</th>\n",
              "      <th>mvar37</th>\n",
              "      <th>mvar38</th>\n",
              "      <th>mvar39</th>\n",
              "      <th>mvar40</th>\n",
              "      <th>mvar41</th>\n",
              "      <th>mvar42</th>\n",
              "      <th>mvar43</th>\n",
              "      <th>mvar44</th>\n",
              "      <th>mvar45</th>\n",
              "      <th>mvar46</th>\n",
              "      <th>mvar47</th>\n",
              "      <th>default_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230032</td>\n",
              "      <td>1696</td>\n",
              "      <td>1.6541</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6015</td>\n",
              "      <td>322</td>\n",
              "      <td>40369</td>\n",
              "      <td>18414</td>\n",
              "      <td>missing</td>\n",
              "      <td>6423</td>\n",
              "      <td>3067</td>\n",
              "      <td>123875</td>\n",
              "      <td>missing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>94.78</td>\n",
              "      <td>8987.18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>72.25</td>\n",
              "      <td>1462</td>\n",
              "      <td>4532</td>\n",
              "      <td>2890</td>\n",
              "      <td>61</td>\n",
              "      <td>4532</td>\n",
              "      <td>1095</td>\n",
              "      <td>3376</td>\n",
              "      <td>625</td>\n",
              "      <td>1.1667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>73.78</td>\n",
              "      <td>82.547</td>\n",
              "      <td>0.08696</td>\n",
              "      <td>10</td>\n",
              "      <td>0.63899</td>\n",
              "      <td>na</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230033</td>\n",
              "      <td>1846</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>102</td>\n",
              "      <td>7532</td>\n",
              "      <td>3171</td>\n",
              "      <td>18234</td>\n",
              "      <td>13664</td>\n",
              "      <td>missing</td>\n",
              "      <td>765</td>\n",
              "      <td>1931</td>\n",
              "      <td>42613</td>\n",
              "      <td>missing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>74.25</td>\n",
              "      <td>953.06</td>\n",
              "      <td>953.06</td>\n",
              "      <td>4.80</td>\n",
              "      <td>1028</td>\n",
              "      <td>2099</td>\n",
              "      <td>2099</td>\n",
              "      <td>30386</td>\n",
              "      <td>2281</td>\n",
              "      <td>missing</td>\n",
              "      <td>2251</td>\n",
              "      <td>169</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>99.129</td>\n",
              "      <td>missing</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0.63836</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>230034</td>\n",
              "      <td>1745</td>\n",
              "      <td>0.4001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>missing</td>\n",
              "      <td>2536</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>2536</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>76109</td>\n",
              "      <td>missing</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>669</td>\n",
              "      <td>4623</td>\n",
              "      <td>3772</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>25.0833</td>\n",
              "      <td>0</td>\n",
              "      <td>na</td>\n",
              "      <td>1</td>\n",
              "      <td>na</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>missing</td>\n",
              "      <td>29.29</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>na</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230035</td>\n",
              "      <td>1739</td>\n",
              "      <td>0.2193</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1982</td>\n",
              "      <td>26440</td>\n",
              "      <td>4955</td>\n",
              "      <td>20316</td>\n",
              "      <td>37013</td>\n",
              "      <td>missing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>84235</td>\n",
              "      <td>missing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1308</td>\n",
              "      <td>2525</td>\n",
              "      <td>791</td>\n",
              "      <td>91</td>\n",
              "      <td>5992</td>\n",
              "      <td>missing</td>\n",
              "      <td>3741</td>\n",
              "      <td>215</td>\n",
              "      <td>10.3333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>96.272</td>\n",
              "      <td>missing</td>\n",
              "      <td>0.15385</td>\n",
              "      <td>3</td>\n",
              "      <td>0.53241</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>230036</td>\n",
              "      <td>1787</td>\n",
              "      <td>0.0118</td>\n",
              "      <td>0.225</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5451</td>\n",
              "      <td>5494</td>\n",
              "      <td>5494</td>\n",
              "      <td>7987</td>\n",
              "      <td>4696</td>\n",
              "      <td>missing</td>\n",
              "      <td>2257</td>\n",
              "      <td>27815</td>\n",
              "      <td>123875</td>\n",
              "      <td>524848</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.51</td>\n",
              "      <td>796.67</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28.72</td>\n",
              "      <td>801</td>\n",
              "      <td>2281</td>\n",
              "      <td>2281</td>\n",
              "      <td>487</td>\n",
              "      <td>2707</td>\n",
              "      <td>missing</td>\n",
              "      <td>1947</td>\n",
              "      <td>158</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>115.019</td>\n",
              "      <td>missing</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92665</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>L</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   application_key mvar1   mvar2  mvar3  ...  mvar45  mvar46 mvar47 default_ind\n",
              "0           230032  1696  1.6541  0.000  ...      na       0      C           0\n",
              "1           230033  1846  0.8095  0.000  ...      na      na      L           1\n",
              "2           230034  1745  0.4001  0.000  ...      na       0      C           1\n",
              "3           230035  1739  0.2193  0.000  ...       0       0      L           0\n",
              "4           230036  1787  0.0118  0.225  ...      na      na      L           0\n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Training data\n",
        "\n",
        "print(train_data.shape)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL1rJSUNxNFb",
        "outputId": "a06ff163-e56b-4b13-e8b6-710768b845ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47000, 48)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_key</th>\n",
              "      <th>mvar1</th>\n",
              "      <th>mvar2</th>\n",
              "      <th>mvar3</th>\n",
              "      <th>mvar4</th>\n",
              "      <th>mvar5</th>\n",
              "      <th>mvar6</th>\n",
              "      <th>mvar7</th>\n",
              "      <th>mvar8</th>\n",
              "      <th>mvar9</th>\n",
              "      <th>mvar10</th>\n",
              "      <th>mvar11</th>\n",
              "      <th>mvar12</th>\n",
              "      <th>mvar13</th>\n",
              "      <th>mvar14</th>\n",
              "      <th>mvar15</th>\n",
              "      <th>mvar16</th>\n",
              "      <th>mvar17</th>\n",
              "      <th>mvar18</th>\n",
              "      <th>mvar19</th>\n",
              "      <th>mvar20</th>\n",
              "      <th>mvar21</th>\n",
              "      <th>mvar22</th>\n",
              "      <th>mvar23</th>\n",
              "      <th>mvar24</th>\n",
              "      <th>mvar25</th>\n",
              "      <th>mvar26</th>\n",
              "      <th>mvar27</th>\n",
              "      <th>mvar28</th>\n",
              "      <th>mvar29</th>\n",
              "      <th>mvar30</th>\n",
              "      <th>mvar31</th>\n",
              "      <th>mvar32</th>\n",
              "      <th>mvar33</th>\n",
              "      <th>mvar34</th>\n",
              "      <th>mvar35</th>\n",
              "      <th>mvar36</th>\n",
              "      <th>mvar37</th>\n",
              "      <th>mvar38</th>\n",
              "      <th>mvar39</th>\n",
              "      <th>mvar40</th>\n",
              "      <th>mvar41</th>\n",
              "      <th>mvar42</th>\n",
              "      <th>mvar43</th>\n",
              "      <th>mvar44</th>\n",
              "      <th>mvar45</th>\n",
              "      <th>mvar46</th>\n",
              "      <th>mvar47</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>578069</td>\n",
              "      <td>1719</td>\n",
              "      <td>0.6174</td>\n",
              "      <td>8.623</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>258</td>\n",
              "      <td>258</td>\n",
              "      <td>258</td>\n",
              "      <td>10729</td>\n",
              "      <td>307</td>\n",
              "      <td>1141</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>49550</td>\n",
              "      <td>83387</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6125.00</td>\n",
              "      <td>1333.33</td>\n",
              "      <td>13.33</td>\n",
              "      <td>1399</td>\n",
              "      <td>1734</td>\n",
              "      <td>122</td>\n",
              "      <td>0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3437</td>\n",
              "      <td>missing</td>\n",
              "      <td>184</td>\n",
              "      <td>5.1667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>0.54545</td>\n",
              "      <td>2</td>\n",
              "      <td>0.91837</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>578070</td>\n",
              "      <td>1795</td>\n",
              "      <td>0.2051</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1685</td>\n",
              "      <td>12711</td>\n",
              "      <td>8913</td>\n",
              "      <td>80519</td>\n",
              "      <td>18099</td>\n",
              "      <td>missing</td>\n",
              "      <td>3457</td>\n",
              "      <td>455</td>\n",
              "      <td>198200</td>\n",
              "      <td>458833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.050</td>\n",
              "      <td>2385.71</td>\n",
              "      <td>2385.71</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1440</td>\n",
              "      <td>2464</td>\n",
              "      <td>2220</td>\n",
              "      <td>760</td>\n",
              "      <td>7330</td>\n",
              "      <td>2525</td>\n",
              "      <td>missing</td>\n",
              "      <td>852</td>\n",
              "      <td>3.0833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>0.17241</td>\n",
              "      <td>4</td>\n",
              "      <td>0.94563</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>578071</td>\n",
              "      <td>1742</td>\n",
              "      <td>0.5082</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1185</td>\n",
              "      <td>8954</td>\n",
              "      <td>8954</td>\n",
              "      <td>1189</td>\n",
              "      <td>1185</td>\n",
              "      <td>missing</td>\n",
              "      <td>3028</td>\n",
              "      <td>1453</td>\n",
              "      <td>122884</td>\n",
              "      <td>missing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.340</td>\n",
              "      <td>33.33</td>\n",
              "      <td>33.33</td>\n",
              "      <td>0.33</td>\n",
              "      <td>2716</td>\n",
              "      <td>5384</td>\n",
              "      <td>5384</td>\n",
              "      <td>669</td>\n",
              "      <td>14478</td>\n",
              "      <td>3711</td>\n",
              "      <td>missing</td>\n",
              "      <td>625</td>\n",
              "      <td>0.5833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>0.64706</td>\n",
              "      <td>1</td>\n",
              "      <td>0.97054</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>578072</td>\n",
              "      <td>1685</td>\n",
              "      <td>0.2595</td>\n",
              "      <td>25.409</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>missing</td>\n",
              "      <td>3354</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>3354</td>\n",
              "      <td>4231</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>118920</td>\n",
              "      <td>375589</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>0</td>\n",
              "      <td>2373</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0</td>\n",
              "      <td>na</td>\n",
              "      <td>6</td>\n",
              "      <td>na</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>0.85714</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>na</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>578073</td>\n",
              "      <td>1666</td>\n",
              "      <td>1.2678</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>570</td>\n",
              "      <td>570</td>\n",
              "      <td>570</td>\n",
              "      <td>missing</td>\n",
              "      <td>570</td>\n",
              "      <td>missing</td>\n",
              "      <td>74</td>\n",
              "      <td>missing</td>\n",
              "      <td>42613</td>\n",
              "      <td>missing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11.538</td>\n",
              "      <td>1153.85</td>\n",
              "      <td>1153.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1551</td>\n",
              "      <td>30</td>\n",
              "      <td>missing</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>missing</td>\n",
              "      <td>101.61</td>\n",
              "      <td>missing</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99617</td>\n",
              "      <td>na</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   application_key mvar1   mvar2   mvar3  ...   mvar44  mvar45 mvar46 mvar47\n",
              "0           578069  1719  0.6174   8.623  ...  0.91837       0      0      C\n",
              "1           578070  1795  0.2051   0.000  ...  0.94563       0      0      C\n",
              "2           578071  1742  0.5082   0.000  ...  0.97054       0      0      C\n",
              "3           578072  1685  0.2595  25.409  ...  1.00000      na      0      C\n",
              "4           578073  1666  1.2678   0.000  ...  0.99617      na      0      L\n",
              "\n",
              "[5 rows x 48 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Test data \n",
        "\n",
        "print(test_data.shape)\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFdoISZHhF7_"
      },
      "source": [
        "## (B) Data Cleaning and Preprocessing of Training and Test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0EedmerxNFc"
      },
      "source": [
        "### Checking for missing values and converting all missing values to NaN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy55HjDjxNFd"
      },
      "source": [
        "We notice that all missing values are not given the value 'NaN'. Some of them are named with different placeholders like 'missing' and 'na'. We need to find out all such placeholders and replace them with NaN.\n",
        "\n",
        "Steps\n",
        "1. Finding out all placeholders that represent missing values (from both train and test datasets)\n",
        "2. Replacing all such placeholders with 'NaN' (for both train and test datasets)\n",
        "\n",
        "**Note**: Here, we assume that the missing value placeholder information (ie the knowledge of whether the missing value was named as 'missing', 'na' or NaN) is not useful for our prediction. It is with this assumption that we perform step 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmL-n40OxNFd"
      },
      "source": [
        "**Step 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzCREwBLxNFe",
        "outputId": "4124c04c-0e0d-42f4-c23a-81cc6fdfba11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique non-numerical values in train dataset =  {'C', 'L', 'na', 'missing'}\n",
            "Unique non-numerical values in test dataset =  {'L', 'na', 'C', 'missing'}\n"
          ]
        }
      ],
      "source": [
        "# This function checks whether a string is a float-type or not\n",
        "def is_float(string):\n",
        "  try:\n",
        "      float(string)\n",
        "      return True\n",
        "  except ValueError:\n",
        "      return False\n",
        "\n",
        "# This function extracts the unique non-numerical values from all columns of a dataset\n",
        "def extract_unique_non_numerics(data):\n",
        "  A  = data.values.reshape(-1)\n",
        "  unique_non_numerics = set([a for a in A if not is_float(str(a))])\n",
        "  return unique_non_numerics\n",
        "\n",
        "\n",
        "print(\"Unique non-numerical values in train dataset = \",extract_unique_non_numerics(train_data) )\n",
        "print(\"Unique non-numerical values in test dataset = \",extract_unique_non_numerics(test_data) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km2RWXA8xNFf"
      },
      "source": [
        "By inspection, C and L are categories of a categorical variable, mvar47. 'missing' and 'na' are the placeholders for missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoISDj9fxNFg"
      },
      "source": [
        "**Step 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfIXjgvLxNFg"
      },
      "outputs": [],
      "source": [
        "missing_map = {'missing': np.nan, 'na': np.nan}\n",
        "train_data_with_NaN = train_data.replace(missing_map)\n",
        "test_data_with_NaN = test_data.replace(missing_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2y-3Kt6xNFk"
      },
      "source": [
        "### Label encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt2nG92DxNFl"
      },
      "source": [
        "We could check which columns need encoding by inspecting train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSfaeoabxNFl",
        "outputId": "6e5334df-3e39-42d1-fe2c-07567969c92e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_key</th>\n",
              "      <th>mvar1</th>\n",
              "      <th>mvar2</th>\n",
              "      <th>mvar3</th>\n",
              "      <th>mvar4</th>\n",
              "      <th>mvar5</th>\n",
              "      <th>mvar6</th>\n",
              "      <th>mvar7</th>\n",
              "      <th>mvar8</th>\n",
              "      <th>mvar9</th>\n",
              "      <th>mvar10</th>\n",
              "      <th>mvar11</th>\n",
              "      <th>mvar12</th>\n",
              "      <th>mvar13</th>\n",
              "      <th>mvar14</th>\n",
              "      <th>mvar15</th>\n",
              "      <th>mvar16</th>\n",
              "      <th>mvar17</th>\n",
              "      <th>mvar18</th>\n",
              "      <th>mvar19</th>\n",
              "      <th>mvar20</th>\n",
              "      <th>mvar21</th>\n",
              "      <th>mvar22</th>\n",
              "      <th>mvar23</th>\n",
              "      <th>mvar24</th>\n",
              "      <th>mvar25</th>\n",
              "      <th>mvar26</th>\n",
              "      <th>mvar27</th>\n",
              "      <th>mvar28</th>\n",
              "      <th>mvar29</th>\n",
              "      <th>mvar30</th>\n",
              "      <th>mvar31</th>\n",
              "      <th>mvar32</th>\n",
              "      <th>mvar33</th>\n",
              "      <th>mvar34</th>\n",
              "      <th>mvar35</th>\n",
              "      <th>mvar36</th>\n",
              "      <th>mvar37</th>\n",
              "      <th>mvar38</th>\n",
              "      <th>mvar39</th>\n",
              "      <th>mvar40</th>\n",
              "      <th>mvar41</th>\n",
              "      <th>mvar42</th>\n",
              "      <th>mvar43</th>\n",
              "      <th>mvar44</th>\n",
              "      <th>mvar45</th>\n",
              "      <th>mvar46</th>\n",
              "      <th>mvar47</th>\n",
              "      <th>default_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230032</td>\n",
              "      <td>1696</td>\n",
              "      <td>1.6541</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6015</td>\n",
              "      <td>322</td>\n",
              "      <td>40369</td>\n",
              "      <td>18414</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6423</td>\n",
              "      <td>3067</td>\n",
              "      <td>123875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>94.78</td>\n",
              "      <td>8987.18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>72.25</td>\n",
              "      <td>1462</td>\n",
              "      <td>4532</td>\n",
              "      <td>2890</td>\n",
              "      <td>61</td>\n",
              "      <td>4532</td>\n",
              "      <td>1095</td>\n",
              "      <td>3376</td>\n",
              "      <td>625</td>\n",
              "      <td>1.1667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>73.78</td>\n",
              "      <td>82.547</td>\n",
              "      <td>0.08696</td>\n",
              "      <td>10</td>\n",
              "      <td>0.63899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230033</td>\n",
              "      <td>1846</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>102</td>\n",
              "      <td>7532</td>\n",
              "      <td>3171</td>\n",
              "      <td>18234</td>\n",
              "      <td>13664</td>\n",
              "      <td>NaN</td>\n",
              "      <td>765</td>\n",
              "      <td>1931</td>\n",
              "      <td>42613</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>74.25</td>\n",
              "      <td>953.06</td>\n",
              "      <td>953.06</td>\n",
              "      <td>4.80</td>\n",
              "      <td>1028</td>\n",
              "      <td>2099</td>\n",
              "      <td>2099</td>\n",
              "      <td>30386</td>\n",
              "      <td>2281</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2251</td>\n",
              "      <td>169</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>99.129</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0.63836</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>230034</td>\n",
              "      <td>1745</td>\n",
              "      <td>0.4001</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2536</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2536</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>76109</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>669</td>\n",
              "      <td>4623</td>\n",
              "      <td>3772</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0833</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29.29</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230035</td>\n",
              "      <td>1739</td>\n",
              "      <td>0.2193</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1982</td>\n",
              "      <td>26440</td>\n",
              "      <td>4955</td>\n",
              "      <td>20316</td>\n",
              "      <td>37013</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>84235</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1308</td>\n",
              "      <td>2525</td>\n",
              "      <td>791</td>\n",
              "      <td>91</td>\n",
              "      <td>5992</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3741</td>\n",
              "      <td>215</td>\n",
              "      <td>10.3333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>96.272</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.15385</td>\n",
              "      <td>3</td>\n",
              "      <td>0.53241</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>230036</td>\n",
              "      <td>1787</td>\n",
              "      <td>0.0118</td>\n",
              "      <td>0.225</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5451</td>\n",
              "      <td>5494</td>\n",
              "      <td>5494</td>\n",
              "      <td>7987</td>\n",
              "      <td>4696</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2257</td>\n",
              "      <td>27815</td>\n",
              "      <td>123875</td>\n",
              "      <td>524848</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.51</td>\n",
              "      <td>796.67</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28.72</td>\n",
              "      <td>801</td>\n",
              "      <td>2281</td>\n",
              "      <td>2281</td>\n",
              "      <td>487</td>\n",
              "      <td>2707</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1947</td>\n",
              "      <td>158</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>115.019</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92665</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   application_key mvar1   mvar2  mvar3  ...  mvar45  mvar46 mvar47 default_ind\n",
              "0           230032  1696  1.6541  0.000  ...     NaN       0      C           0\n",
              "1           230033  1846  0.8095  0.000  ...     NaN     NaN      L           1\n",
              "2           230034  1745  0.4001  0.000  ...     NaN       0      C           1\n",
              "3           230035  1739  0.2193  0.000  ...       0       0      L           0\n",
              "4           230036  1787  0.0118  0.225  ...     NaN     NaN      L           0\n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "train_data_with_NaN.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIwkOkI4xNFl",
        "outputId": "aaf3891e-9b16-412b-a8df-dfd7ce7a70a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_key</th>\n",
              "      <th>mvar1</th>\n",
              "      <th>mvar2</th>\n",
              "      <th>mvar3</th>\n",
              "      <th>mvar4</th>\n",
              "      <th>mvar5</th>\n",
              "      <th>mvar6</th>\n",
              "      <th>mvar7</th>\n",
              "      <th>mvar8</th>\n",
              "      <th>mvar9</th>\n",
              "      <th>mvar10</th>\n",
              "      <th>mvar11</th>\n",
              "      <th>mvar12</th>\n",
              "      <th>mvar13</th>\n",
              "      <th>mvar14</th>\n",
              "      <th>mvar15</th>\n",
              "      <th>mvar16</th>\n",
              "      <th>mvar17</th>\n",
              "      <th>mvar18</th>\n",
              "      <th>mvar19</th>\n",
              "      <th>mvar20</th>\n",
              "      <th>mvar21</th>\n",
              "      <th>mvar22</th>\n",
              "      <th>mvar23</th>\n",
              "      <th>mvar24</th>\n",
              "      <th>mvar25</th>\n",
              "      <th>mvar26</th>\n",
              "      <th>mvar27</th>\n",
              "      <th>mvar28</th>\n",
              "      <th>mvar29</th>\n",
              "      <th>mvar30</th>\n",
              "      <th>mvar31</th>\n",
              "      <th>mvar32</th>\n",
              "      <th>mvar33</th>\n",
              "      <th>mvar34</th>\n",
              "      <th>mvar35</th>\n",
              "      <th>mvar36</th>\n",
              "      <th>mvar37</th>\n",
              "      <th>mvar38</th>\n",
              "      <th>mvar39</th>\n",
              "      <th>mvar40</th>\n",
              "      <th>mvar41</th>\n",
              "      <th>mvar42</th>\n",
              "      <th>mvar43</th>\n",
              "      <th>mvar44</th>\n",
              "      <th>mvar45</th>\n",
              "      <th>mvar46</th>\n",
              "      <th>mvar47</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>578069</td>\n",
              "      <td>1719</td>\n",
              "      <td>0.6174</td>\n",
              "      <td>8.623</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>258</td>\n",
              "      <td>258</td>\n",
              "      <td>258</td>\n",
              "      <td>10729</td>\n",
              "      <td>307</td>\n",
              "      <td>1141</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>49550</td>\n",
              "      <td>83387</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6125.00</td>\n",
              "      <td>1333.33</td>\n",
              "      <td>13.33</td>\n",
              "      <td>1399</td>\n",
              "      <td>1734</td>\n",
              "      <td>122</td>\n",
              "      <td>0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3437</td>\n",
              "      <td>NaN</td>\n",
              "      <td>184</td>\n",
              "      <td>5.1667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.54545</td>\n",
              "      <td>2</td>\n",
              "      <td>0.91837</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>578070</td>\n",
              "      <td>1795</td>\n",
              "      <td>0.2051</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1685</td>\n",
              "      <td>12711</td>\n",
              "      <td>8913</td>\n",
              "      <td>80519</td>\n",
              "      <td>18099</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3457</td>\n",
              "      <td>455</td>\n",
              "      <td>198200</td>\n",
              "      <td>458833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.050</td>\n",
              "      <td>2385.71</td>\n",
              "      <td>2385.71</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1440</td>\n",
              "      <td>2464</td>\n",
              "      <td>2220</td>\n",
              "      <td>760</td>\n",
              "      <td>7330</td>\n",
              "      <td>2525</td>\n",
              "      <td>NaN</td>\n",
              "      <td>852</td>\n",
              "      <td>3.0833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.17241</td>\n",
              "      <td>4</td>\n",
              "      <td>0.94563</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>578071</td>\n",
              "      <td>1742</td>\n",
              "      <td>0.5082</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1185</td>\n",
              "      <td>8954</td>\n",
              "      <td>8954</td>\n",
              "      <td>1189</td>\n",
              "      <td>1185</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3028</td>\n",
              "      <td>1453</td>\n",
              "      <td>122884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.340</td>\n",
              "      <td>33.33</td>\n",
              "      <td>33.33</td>\n",
              "      <td>0.33</td>\n",
              "      <td>2716</td>\n",
              "      <td>5384</td>\n",
              "      <td>5384</td>\n",
              "      <td>669</td>\n",
              "      <td>14478</td>\n",
              "      <td>3711</td>\n",
              "      <td>NaN</td>\n",
              "      <td>625</td>\n",
              "      <td>0.5833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.64706</td>\n",
              "      <td>1</td>\n",
              "      <td>0.97054</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>578072</td>\n",
              "      <td>1685</td>\n",
              "      <td>0.2595</td>\n",
              "      <td>25.409</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3354</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3354</td>\n",
              "      <td>4231</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>118920</td>\n",
              "      <td>375589</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2373</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.85714</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>578073</td>\n",
              "      <td>1666</td>\n",
              "      <td>1.2678</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>570</td>\n",
              "      <td>570</td>\n",
              "      <td>570</td>\n",
              "      <td>NaN</td>\n",
              "      <td>570</td>\n",
              "      <td>NaN</td>\n",
              "      <td>74</td>\n",
              "      <td>NaN</td>\n",
              "      <td>42613</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11.538</td>\n",
              "      <td>1153.85</td>\n",
              "      <td>1153.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1551</td>\n",
              "      <td>30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101.61</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99617</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   application_key mvar1   mvar2   mvar3  ...   mvar44  mvar45 mvar46 mvar47\n",
              "0           578069  1719  0.6174   8.623  ...  0.91837       0      0      C\n",
              "1           578070  1795  0.2051   0.000  ...  0.94563       0      0      C\n",
              "2           578071  1742  0.5082   0.000  ...  0.97054       0      0      C\n",
              "3           578072  1685  0.2595  25.409  ...  1.00000     NaN      0      C\n",
              "4           578073  1666  1.2678   0.000  ...  0.99617     NaN      0      L\n",
              "\n",
              "[5 rows x 48 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "test_data_with_NaN.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnGN8sVFxNFm"
      },
      "source": [
        "By inspection, we can find that all columns except mvar47 are numerical and does not need encoding. Since mvar47 contains only C and L as categories, we can use a Label encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2dBkaFjxNFm",
        "outputId": "b6b1b5a1-67cb-475a-af86-6cb950b343ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n"
          ]
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "train_data_with_NaN[['mvar47']] = le.fit_transform(train_data_with_NaN[['mvar47']])\n",
        "test_data_with_NaN[['mvar47']] = le.transform(test_data_with_NaN[['mvar47']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJarxNeQhg_L"
      },
      "source": [
        "###  Datatype correction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guC8hYQlxNFn"
      },
      "source": [
        "Now that all the columns are numerical, we can convert all of them to float datatype for uniformity\n",
        "\n",
        "(Except application key which is just an id and default_index which is our classification target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN3jeupkxNFn"
      },
      "outputs": [],
      "source": [
        "train_data_with_NaN = train_data_with_NaN.astype('float')\n",
        "test_data_with_NaN = test_data_with_NaN.astype('float')\n",
        "\n",
        "train_data_with_NaN['application_key'] = train_data_with_NaN.application_key.astype('int')\n",
        "test_data_with_NaN['application_key'] = test_data_with_NaN.application_key.astype('int')\n",
        "\n",
        "train_data_with_NaN['default_ind'] = train_data_with_NaN.default_ind.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlqCih3txNFo"
      },
      "source": [
        "### Checking for class imbalance in the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L22VtU4PxNFo",
        "outputId": "8e59696b-9bc1-4bf3-cf20-f65eafe0067c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    59145\n",
            "1    23855\n",
            "Name: default_ind, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "train_data_target_split= train_data_with_NaN.default_ind.value_counts()\n",
        "print(train_data_target_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7VIL0RmxNFp"
      },
      "source": [
        "We can see that there is some level of class imbalance in the training data\n",
        "\n",
        "**We need to use imbalance correction hyperparameter for XGBoost and LightGBM (this variable will be used later during model training)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khJPwLSzxNFq",
        "outputId": "e1f6cfe2-e257-4da5-fc1e-3030030bd969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.479354433032907\n"
          ]
        }
      ],
      "source": [
        "scale_pos_weight_data = train_data_target_split.values.astype('float')[0]/train_data_target_split.values.astype('float')[1]\n",
        "print(scale_pos_weight_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mWO66QRxNFr"
      },
      "source": [
        "### Dealing with missing values: Imputing the others with the mean of the column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3jpwEqIjrMa"
      },
      "source": [
        "We impute the missing values with the mean of the column it belongs to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz6hI2-fxNFr"
      },
      "outputs": [],
      "source": [
        "# print(\"Train dataset shape before dropping rows and columns: \",train_data_with_NaN.shape)\n",
        "\n",
        "# # Dropping columns\n",
        "# threshold_columns = train_data_with_NaN.shape[0] * .7\n",
        "# columns1 = train_data_with_NaN.columns\n",
        "# train_data_with_NaN = train_data_with_NaN.dropna(thresh=threshold_columns, axis=1)  # dropping poor columns of train data\n",
        "# columns2 = train_data_with_NaN.columns\n",
        "# dropped_columns = set(columns1)-set(columns2)\n",
        "# test_data_with_NaN = test_data_with_NaN.drop(dropped_columns,axis=1)                # dropping corresponding columns of test data \n",
        "\n",
        "# # Dropping rows\n",
        "# threshold_rows = train_data_with_NaN.shape[1] * .7\n",
        "# train_data_with_NaN = train_data_with_NaN.dropna(thresh=threshold_rows, axis=0)  # dropping poor rows of train data\n",
        "\n",
        "# print(\"Train dataset shape after dropping rows and columns: \",train_data_with_NaN.shape)\n",
        "\n",
        "# Imputing with mean\n",
        "train_data = train_data_with_NaN.fillna(train_data_with_NaN.mean())\n",
        "test_data = test_data_with_NaN.fillna(test_data_with_NaN.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIVdCSH3lvH9"
      },
      "source": [
        "### Final input columns and output columns ready for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KV44frs9l2HX"
      },
      "outputs": [],
      "source": [
        "X_train = train_data.drop(['default_ind'],axis=1)\n",
        "Y_train=train_data.default_ind.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKiH4nUNnHDy"
      },
      "source": [
        "## EDA: (Not completed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrjsNPXjnJm2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFIOU-nam9x3"
      },
      "source": [
        "## (C) Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFbBIXAfpR98"
      },
      "source": [
        "### We use crossvalidation (on the scaled dataset) to find the best model \n",
        "\n",
        "#####(We are not sure which scoring criteria is used in the leaderboard. We arbitrarily used f1 score in this case)\n",
        "\n",
        "Note: We use stratified k fold cross validation since it is an imbalanced dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUN_UKhl2DXb"
      },
      "source": [
        "### Scaling and setting up the stratified k fold cross validation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHZqTBPK132I",
        "outputId": "cf504b4b-a45d-425d-b476-87271176a43b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average f1 scores in cross validation: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Scaling X_train\n",
        "X_train_unscaled = X_train  # saving the unscaled for later use\n",
        "scaler = MinMaxScaler();\n",
        "X_train = scaler.fit_transform(X_train_unscaled);\n",
        "\n",
        "print(\"Average f1 scores in cross validation: \\n\")\n",
        "k_fold = StratifiedKFold(n_splits=5, shuffle=True)  # We use stratified k fold cross validation since it is an imbalanced dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH-lSR_wgagO"
      },
      "source": [
        "### 1: Trying out different models individually\n",
        " We have tried almost all models taught in class (except SupportVectorClassifier, which is very time consuming)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQyZOY38nBoj",
        "outputId": "f4134f3a-6977-4ecc-b30e-7bf70043d54b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:  0.47986853737210433\n",
            "KNN:  0.4502791854895934\n",
            "Decision Tree:  0.45018836100080034\n",
            "Random Forest:  0.5014614095399285\n",
            "Bagging:  0.4658905386083025\n",
            "LGBM:  0.5909863763158778\n",
            "XGBoost:  0.588793027309474\n",
            "AdaBoost:  0.49773221056003275\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)  # Doesn't converge unless we increase max iterations\n",
        "model_f1scores = cross_val_score(estimator = model, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "print(\"Logistic Regression: \",model_f1scores.mean())\n",
        "\n",
        "# KNN\n",
        "model = KNeighborsClassifier()\n",
        "model_f1scores = cross_val_score(estimator = model, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "print(\"KNN: \",model_f1scores.mean())\n",
        "\n",
        "# DecisionTree\n",
        "model = DecisionTreeClassifier()\n",
        "model_f1scores = cross_val_score(estimator = model, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "print(\"Decision Tree: \",model_f1scores.mean())\n",
        "\n",
        "# RandomForest\n",
        "model = RandomForestClassifier()\n",
        "model_f1scores = cross_val_score(estimator = model, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "print(\"Random Forest: \",model_f1scores.mean())\n",
        "\n",
        "# Bagging\n",
        "model = BaggingClassifier()\n",
        "model_f1scores = cross_val_score(estimator = model, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "print(\"Bagging: \",model_f1scores.mean())\n",
        "\n",
        "# LGBMClassifier\n",
        "model = LGBMClassifier(scale_pos_weight=scale_pos_weight_data)\n",
        "model_f1scores = cross_val_score(estimator = model, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "print(\"LGBM: \",model_f1scores.mean())\n",
        "\n",
        "# XGBoost\n",
        "model = XGBClassifier(scale_pos_weight=scale_pos_weight_data)\n",
        "model_f1scores = cross_val_score(estimator = model, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "print(\"XGBoost: \",model_f1scores.mean())\n",
        "\n",
        "# AdaBoost\n",
        "model = AdaBoostClassifier()\n",
        "model_f1scores = cross_val_score(estimator = model, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "print(\"AdaBoost: \",model_f1scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJxdjz2f0DUD"
      },
      "source": [
        "### Result: LGBM and XGBoost works the best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qtlvqyIhHx8"
      },
      "source": [
        "### 2: Voting classifier of LGBM and XGBoost (Both soft and hard voting are tried)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b248VXjudPOR",
        "outputId": "20bb5b8b-9123-45cc-b293-e8dadf78fd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soft Voting of LGBM and XGBoost:  0.5909822243942535\n",
            "Hard Voting of LGBM and XGBoost:  0.5914601363747639\n"
          ]
        }
      ],
      "source": [
        "estimators = []\n",
        "\n",
        "model_1 = LGBMClassifier(scale_pos_weight=scale_pos_weight_data)\n",
        "estimators.append(('lgbm', model_1))\n",
        "\n",
        "model_2 =XGBClassifier(scale_pos_weight=scale_pos_weight_data)\n",
        "estimators.append(('xgb', model_2))\n",
        "\n",
        "# Voting Classifier (Soft voting)\n",
        "model = VotingClassifier(estimators, voting='soft')\n",
        "model_f1scores = cross_val_score(estimator = model, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "print(\"Soft Voting of LGBM and XGBoost: \",model_f1scores.mean())\n",
        "\n",
        "# Voting Classifier (Hard voting)\n",
        "model = VotingClassifier(estimators, voting='hard')\n",
        "model_f1scores = cross_val_score(estimator = model, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "print(\"Hard Voting of LGBM and XGBoost: \",model_f1scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOOxbDig20Nc"
      },
      "source": [
        "### Results\n",
        "\n",
        "The following models are selected (all four have almost same accuracy)\n",
        "\n",
        "1. Light Gradient Boosted Machine (LGBM)\n",
        "2. XGBoost\n",
        "3. Soft Voting of 1 and 2\n",
        "4. Hard Voting of 1 and 2\n",
        "\n",
        "Default hyperparameters were given till now\n",
        "(except scale_pos_weight which was assigned imbalance correction factor taken from the training dataset: Refer the portion on checking imbalance in (B))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLMMRA9DiO9f"
      },
      "source": [
        "## (D) Hyperparameter Tuning\n",
        "\n",
        "From Model selection we have XGBoost, LightGBM and their voting (soft and hard) as the best models.\n",
        "\n",
        "**We perform tuning only for hyperparameters in LightGBM**, (Since cross validation for XGBoost is time consuming)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGMC-GjO7lJe"
      },
      "source": [
        "### Scaling and setting up the stratified k fold cross validation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yybhZjec7lJe"
      },
      "outputs": [],
      "source": [
        "# Scaling X_train\n",
        "scaler = MinMaxScaler();\n",
        "X_train = scaler.fit_transform(X_train_unscaled);\n",
        "\n",
        "k_fold = StratifiedKFold(n_splits=5, shuffle=True)  # We use stratified k fold cross validation since it is an imbalanced dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1oQT0WY8CI4"
      },
      "source": [
        "### 1: Hyperparameter tuning for LightGBM\n",
        "\n",
        "(tune most hyperparameters of LightGBM except scale_pos_weight(which is given the same value as before))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHO2WQoYBn92",
        "outputId": "ff2f8766-dda9-4b62-c95e-2b957e1288b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-12-10 05:46:55,803]\u001b[0m A new study created in memory with name: no-name-5bd40cde-7f41-4a79-9064-b0da8a9d28f3\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:47:38,662]\u001b[0m Trial 0 finished with value: 0.5858901695709269 and parameters: {'n_estimators': 760, 'max_depth': 93, 'learning_rate': 0.07453924112489263, 'subsample': 0.5985016910548367, 'colsample_bytree': 0.4978558810958312}. Best is trial 0 with value: 0.5858901695709269.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:48:29,554]\u001b[0m Trial 1 finished with value: 0.5685601197601337 and parameters: {'n_estimators': 756, 'max_depth': 32, 'learning_rate': 0.16561275792170393, 'subsample': 0.9678121860159825, 'colsample_bytree': 0.769384480726603}. Best is trial 0 with value: 0.5858901695709269.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:49:08,927]\u001b[0m Trial 2 finished with value: 0.5909766205276151 and parameters: {'n_estimators': 444, 'max_depth': 17, 'learning_rate': 0.04687531646866458, 'subsample': 0.5929496646741004, 'colsample_bytree': 0.7908704158098248}. Best is trial 2 with value: 0.5909766205276151.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:49:49,341]\u001b[0m Trial 3 finished with value: 0.5559300984910746 and parameters: {'n_estimators': 832, 'max_depth': 38, 'learning_rate': 0.20270303536654266, 'subsample': 0.8913490830972053, 'colsample_bytree': 0.44921246650934554}. Best is trial 2 with value: 0.5909766205276151.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:50:19,892]\u001b[0m Trial 4 finished with value: 0.5860666732956618 and parameters: {'n_estimators': 334, 'max_depth': 48, 'learning_rate': 0.11230163470343396, 'subsample': 0.6617693149022512, 'colsample_bytree': 0.9465636516086111}. Best is trial 2 with value: 0.5909766205276151.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:50:43,613]\u001b[0m Trial 5 finished with value: 0.5867331028085531 and parameters: {'n_estimators': 334, 'max_depth': 56, 'learning_rate': 0.1367250980077763, 'subsample': 0.33542119932812087, 'colsample_bytree': 0.6871233199888112}. Best is trial 2 with value: 0.5909766205276151.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:50:55,336]\u001b[0m Trial 6 finished with value: 0.5870000692011728 and parameters: {'n_estimators': 153, 'max_depth': 55, 'learning_rate': 0.17178730171562318, 'subsample': 0.4538825365449074, 'colsample_bytree': 0.5442819390106794}. Best is trial 2 with value: 0.5909766205276151.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:52:18,358]\u001b[0m Trial 7 finished with value: 0.5910388919872892 and parameters: {'n_estimators': 947, 'max_depth': 6, 'learning_rate': 0.029585701851155125, 'subsample': 0.9361377971970521, 'colsample_bytree': 0.8693103730937806}. Best is trial 7 with value: 0.5910388919872892.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:52:57,578]\u001b[0m Trial 8 finished with value: 0.5803492207446744 and parameters: {'n_estimators': 997, 'max_depth': 12, 'learning_rate': 0.09491065411114698, 'subsample': 0.7226916136542465, 'colsample_bytree': 0.25668517105322036}. Best is trial 7 with value: 0.5910388919872892.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:53:27,135]\u001b[0m Trial 9 finished with value: 0.5910112447711455 and parameters: {'n_estimators': 356, 'max_depth': 75, 'learning_rate': 0.015592359553726039, 'subsample': 0.24996134355038555, 'colsample_bytree': 0.427817242433987}. Best is trial 7 with value: 0.5910388919872892.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:53:53,976]\u001b[0m Trial 10 finished with value: 0.5899655044479035 and parameters: {'n_estimators': 642, 'max_depth': 1, 'learning_rate': 0.2832701766914166, 'subsample': 0.8064444856825806, 'colsample_bytree': 0.9803980206945564}. Best is trial 7 with value: 0.5910388919872892.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:54:02,624]\u001b[0m Trial 11 finished with value: 0.5865252598934421 and parameters: {'n_estimators': 94, 'max_depth': 82, 'learning_rate': 0.024894277680261895, 'subsample': 0.3511109327626478, 'colsample_bytree': 0.3058146238083283}. Best is trial 7 with value: 0.5910388919872892.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:54:43,224]\u001b[0m Trial 12 finished with value: 0.5920709739436429 and parameters: {'n_estimators': 550, 'max_depth': 73, 'learning_rate': 0.010158031851774278, 'subsample': 0.22268896093328377, 'colsample_bytree': 0.37397017725860826}. Best is trial 12 with value: 0.5920709739436429.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:55:48,475]\u001b[0m Trial 13 finished with value: 0.5855349244901145 and parameters: {'n_estimators': 998, 'max_depth': 68, 'learning_rate': 0.06050523445752354, 'subsample': 0.4897015770110769, 'colsample_bytree': 0.6599264569133506}. Best is trial 12 with value: 0.5920709739436429.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:56:54,109]\u001b[0m Trial 14 finished with value: 0.5912109072889049 and parameters: {'n_estimators': 571, 'max_depth': 98, 'learning_rate': 0.013401948030753147, 'subsample': 0.9935600118561256, 'colsample_bytree': 0.8532480109663936}. Best is trial 12 with value: 0.5920709739436429.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:57:19,563]\u001b[0m Trial 15 finished with value: 0.5642157393294228 and parameters: {'n_estimators': 596, 'max_depth': 96, 'learning_rate': 0.25819919871209496, 'subsample': 0.21403610487058378, 'colsample_bytree': 0.3474884886038147}. Best is trial 12 with value: 0.5920709739436429.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:57:49,227]\u001b[0m Trial 16 finished with value: 0.5903054755147888 and parameters: {'n_estimators': 532, 'max_depth': 100, 'learning_rate': 0.012264905678736282, 'subsample': 0.8081208574671197, 'colsample_bytree': 0.20830759741014654}. Best is trial 12 with value: 0.5920709739436429.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:58:20,514]\u001b[0m Trial 17 finished with value: 0.5879996600870718 and parameters: {'n_estimators': 463, 'max_depth': 84, 'learning_rate': 0.08577539714755067, 'subsample': 0.48677248583059873, 'colsample_bytree': 0.6235415566502835}. Best is trial 12 with value: 0.5920709739436429.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:59:05,984]\u001b[0m Trial 18 finished with value: 0.5616802244077739 and parameters: {'n_estimators': 664, 'max_depth': 67, 'learning_rate': 0.21130173861187262, 'subsample': 0.36364907384641554, 'colsample_bytree': 0.7576879044352599}. Best is trial 12 with value: 0.5920709739436429.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:59:17,521]\u001b[0m Trial 19 finished with value: 0.5889893502692564 and parameters: {'n_estimators': 179, 'max_depth': 90, 'learning_rate': 0.12811660847573736, 'subsample': 0.7965999925304298, 'colsample_bytree': 0.37045183224012734}. Best is trial 12 with value: 0.5920709739436429.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:59:38,120]\u001b[0m Trial 20 finished with value: 0.5925223111119845 and parameters: {'n_estimators': 252, 'max_depth': 73, 'learning_rate': 0.05128479302441449, 'subsample': 0.9970681480831126, 'colsample_bytree': 0.5603540871348338}. Best is trial 20 with value: 0.5925223111119845.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 05:59:58,365]\u001b[0m Trial 21 finished with value: 0.5924160871008134 and parameters: {'n_estimators': 238, 'max_depth': 70, 'learning_rate': 0.049520773816103564, 'subsample': 0.9783060067597016, 'colsample_bytree': 0.5442363539105889}. Best is trial 20 with value: 0.5925223111119845.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:00:18,381]\u001b[0m Trial 22 finished with value: 0.5911535116269346 and parameters: {'n_estimators': 231, 'max_depth': 68, 'learning_rate': 0.04799685177901512, 'subsample': 0.8772922211841855, 'colsample_bytree': 0.5444141754066257}. Best is trial 20 with value: 0.5925223111119845.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:00:26,767]\u001b[0m Trial 23 finished with value: 0.5894868849484347 and parameters: {'n_estimators': 63, 'max_depth': 62, 'learning_rate': 0.06043205042598106, 'subsample': 0.8725620590924512, 'colsample_bytree': 0.5611390363508962}. Best is trial 20 with value: 0.5925223111119845.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:00:43,283]\u001b[0m Trial 24 finished with value: 0.5910876496979882 and parameters: {'n_estimators': 262, 'max_depth': 78, 'learning_rate': 0.10701339443104226, 'subsample': 0.7090499578773921, 'colsample_bytree': 0.4532546742712797}. Best is trial 20 with value: 0.5925223111119845.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:00:47,306]\u001b[0m Trial 25 finished with value: 0.4781525602824244 and parameters: {'n_estimators': 15, 'max_depth': 75, 'learning_rate': 0.04651953212553294, 'subsample': 0.9993794453800137, 'colsample_bytree': 0.6051972482077375}. Best is trial 20 with value: 0.5925223111119845.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:01:09,050]\u001b[0m Trial 26 finished with value: 0.5904855614026479 and parameters: {'n_estimators': 399, 'max_depth': 46, 'learning_rate': 0.08292188571035794, 'subsample': 0.9077694915555701, 'colsample_bytree': 0.3911646560269658}. Best is trial 20 with value: 0.5925223111119845.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:01:30,067]\u001b[0m Trial 27 finished with value: 0.5949157150158333 and parameters: {'n_estimators': 247, 'max_depth': 61, 'learning_rate': 0.03673355471790472, 'subsample': 0.5274172552224983, 'colsample_bytree': 0.49824433467264634}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:01:49,890]\u001b[0m Trial 28 finished with value: 0.5910590157982183 and parameters: {'n_estimators': 275, 'max_depth': 58, 'learning_rate': 0.06646980578218685, 'subsample': 0.5422585123113749, 'colsample_bytree': 0.5051568008728022}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:02:06,762]\u001b[0m Trial 29 finished with value: 0.5930647468059733 and parameters: {'n_estimators': 180, 'max_depth': 89, 'learning_rate': 0.03725164958484266, 'subsample': 0.6373075339071848, 'colsample_bytree': 0.495868860129425}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:02:21,145]\u001b[0m Trial 30 finished with value: 0.591074428538698 and parameters: {'n_estimators': 140, 'max_depth': 89, 'learning_rate': 0.03471343173154869, 'subsample': 0.5512848175075291, 'colsample_bytree': 0.4882259427958825}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:02:40,671]\u001b[0m Trial 31 finished with value: 0.5908364911972829 and parameters: {'n_estimators': 211, 'max_depth': 86, 'learning_rate': 0.07367143720759103, 'subsample': 0.6648549587659447, 'colsample_bytree': 0.693198779859904}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:03:04,914]\u001b[0m Trial 32 finished with value: 0.5927273054423837 and parameters: {'n_estimators': 301, 'max_depth': 64, 'learning_rate': 0.03829914699682271, 'subsample': 0.4468290019063642, 'colsample_bytree': 0.5004303776795723}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:03:29,216]\u001b[0m Trial 33 finished with value: 0.590840153961529 and parameters: {'n_estimators': 285, 'max_depth': 41, 'learning_rate': 0.0309496349096436, 'subsample': 0.4302199261282013, 'colsample_bytree': 0.4996296755172543}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:03:56,397]\u001b[0m Trial 34 finished with value: 0.5865133705401666 and parameters: {'n_estimators': 414, 'max_depth': 64, 'learning_rate': 0.10402044987987248, 'subsample': 0.6011582081964826, 'colsample_bytree': 0.5779789601028736}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:04:07,120]\u001b[0m Trial 35 finished with value: 0.5895590808649809 and parameters: {'n_estimators': 101, 'max_depth': 80, 'learning_rate': 0.040930991415935106, 'subsample': 0.38187540391571334, 'colsample_bytree': 0.446065048495242}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:04:29,992]\u001b[0m Trial 36 finished with value: 0.5869525384177318 and parameters: {'n_estimators': 322, 'max_depth': 51, 'learning_rate': 0.12899214942532547, 'subsample': 0.5697179056249905, 'colsample_bytree': 0.6332401542970758}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:05:06,832]\u001b[0m Trial 37 finished with value: 0.5892901201546876 and parameters: {'n_estimators': 479, 'max_depth': 61, 'learning_rate': 0.07855441727276205, 'subsample': 0.5059525438606566, 'colsample_bytree': 0.7310721461666267}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:05:22,090]\u001b[0m Trial 38 finished with value: 0.5919192517246261 and parameters: {'n_estimators': 175, 'max_depth': 30, 'learning_rate': 0.05583136812811408, 'subsample': 0.6134370640141824, 'colsample_bytree': 0.486459664460465}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:05:40,684]\u001b[0m Trial 39 finished with value: 0.5754879303129294 and parameters: {'n_estimators': 350, 'max_depth': 25, 'learning_rate': 0.20209991033548333, 'subsample': 0.4064109048781035, 'colsample_bytree': 0.4206421051669011}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:05:59,138]\u001b[0m Trial 40 finished with value: 0.5816201188542995 and parameters: {'n_estimators': 396, 'max_depth': 52, 'learning_rate': 0.16915114215226174, 'subsample': 0.27851073544976696, 'colsample_bytree': 0.3192042247723889}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:06:19,488]\u001b[0m Trial 41 finished with value: 0.5925243766462072 and parameters: {'n_estimators': 219, 'max_depth': 71, 'learning_rate': 0.03681111345769995, 'subsample': 0.9702481946676538, 'colsample_bytree': 0.52361615922523}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:06:33,801]\u001b[0m Trial 42 finished with value: 0.5896144916004351 and parameters: {'n_estimators': 125, 'max_depth': 56, 'learning_rate': 0.028243810539132188, 'subsample': 0.9266729759545692, 'colsample_bytree': 0.5247497997833543}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:06:53,716]\u001b[0m Trial 43 finished with value: 0.5932903229205136 and parameters: {'n_estimators': 195, 'max_depth': 77, 'learning_rate': 0.03845763444999075, 'subsample': 0.29720153761541024, 'colsample_bytree': 0.5890685144436598}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:07:00,776]\u001b[0m Trial 44 finished with value: 0.5811990509571723 and parameters: {'n_estimators': 41, 'max_depth': 94, 'learning_rate': 0.035346925786902884, 'subsample': 0.27510508944355583, 'colsample_bytree': 0.589617335324653}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:07:15,482]\u001b[0m Trial 45 finished with value: 0.5898007866789603 and parameters: {'n_estimators': 192, 'max_depth': 79, 'learning_rate': 0.08984246709113203, 'subsample': 0.3148890966371909, 'colsample_bytree': 0.4596821414596712}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:07:37,925]\u001b[0m Trial 46 finished with value: 0.5823604749725024 and parameters: {'n_estimators': 305, 'max_depth': 87, 'learning_rate': 0.14739205275737738, 'subsample': 0.45033342305796736, 'colsample_bytree': 0.6461948014723419}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:07:46,771]\u001b[0m Trial 47 finished with value: 0.5924462572196214 and parameters: {'n_estimators': 86, 'max_depth': 64, 'learning_rate': 0.07093619983550128, 'subsample': 0.6591082497019902, 'colsample_bytree': 0.4111979012819164}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:08:06,383]\u001b[0m Trial 48 finished with value: 0.5895385951144297 and parameters: {'n_estimators': 146, 'max_depth': 71, 'learning_rate': 0.020883025495463538, 'subsample': 0.31135960818321884, 'colsample_bytree': 0.6845980147803491}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:08:27,216]\u001b[0m Trial 49 finished with value: 0.5897445504665261 and parameters: {'n_estimators': 201, 'max_depth': 77, 'learning_rate': 0.025478346455598575, 'subsample': 0.5014288895734579, 'colsample_bytree': 0.5253934873961443}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:09:17,060]\u001b[0m Trial 50 finished with value: 0.5820430840364142 and parameters: {'n_estimators': 814, 'max_depth': 83, 'learning_rate': 0.09541792381922701, 'subsample': 0.7401089048959695, 'colsample_bytree': 0.5894427641943746}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:09:36,610]\u001b[0m Trial 51 finished with value: 0.5912704494221983 and parameters: {'n_estimators': 262, 'max_depth': 74, 'learning_rate': 0.056360866740348195, 'subsample': 0.8390493686206899, 'colsample_bytree': 0.4871994863544687}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:10:05,317]\u001b[0m Trial 52 finished with value: 0.5926255449399258 and parameters: {'n_estimators': 368, 'max_depth': 60, 'learning_rate': 0.03980365956258431, 'subsample': 0.9535644252857183, 'colsample_bytree': 0.5588720173125941}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:10:35,898]\u001b[0m Trial 53 finished with value: 0.5926592737257215 and parameters: {'n_estimators': 377, 'max_depth': 44, 'learning_rate': 0.04001254022199467, 'subsample': 0.9634490891450206, 'colsample_bytree': 0.6084693603729493}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:11:17,038]\u001b[0m Trial 54 finished with value: 0.5895988157986297 and parameters: {'n_estimators': 378, 'max_depth': 41, 'learning_rate': 0.010315298497574829, 'subsample': 0.9385309382495257, 'colsample_bytree': 0.6069320988746597}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:11:50,821]\u001b[0m Trial 55 finished with value: 0.5924396155189967 and parameters: {'n_estimators': 320, 'max_depth': 45, 'learning_rate': 0.021344324529719478, 'subsample': 0.465131195128888, 'colsample_bytree': 0.6669399940143503}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:12:24,569]\u001b[0m Trial 56 finished with value: 0.5890941905973663 and parameters: {'n_estimators': 437, 'max_depth': 35, 'learning_rate': 0.06800171303886691, 'subsample': 0.4066928830533304, 'colsample_bytree': 0.7128391135247767}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:12:58,917]\u001b[0m Trial 57 finished with value: 0.5932782721631276 and parameters: {'n_estimators': 493, 'max_depth': 59, 'learning_rate': 0.04479474384548676, 'subsample': 0.52891668912161, 'colsample_bytree': 0.5582587408057273}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:13:37,061]\u001b[0m Trial 58 finished with value: 0.5829454526559333 and parameters: {'n_estimators': 484, 'max_depth': 55, 'learning_rate': 0.11794580655381035, 'subsample': 0.5331343263614091, 'colsample_bytree': 0.8195855551298629}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:14:08,004]\u001b[0m Trial 59 finished with value: 0.5901139580630093 and parameters: {'n_estimators': 524, 'max_depth': 48, 'learning_rate': 0.061824433213704774, 'subsample': 0.623639374207169, 'colsample_bytree': 0.4672624237882864}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:14:36,113]\u001b[0m Trial 60 finished with value: 0.5714564005285696 and parameters: {'n_estimators': 448, 'max_depth': 66, 'learning_rate': 0.18976590360902135, 'subsample': 0.580267987386575, 'colsample_bytree': 0.6212188592023556}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:15:03,986]\u001b[0m Trial 61 finished with value: 0.5919845945525409 and parameters: {'n_estimators': 359, 'max_depth': 59, 'learning_rate': 0.043352690697647134, 'subsample': 0.5258924526873678, 'colsample_bytree': 0.5643602329551881}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:15:44,119]\u001b[0m Trial 62 finished with value: 0.5907748922743998 and parameters: {'n_estimators': 604, 'max_depth': 52, 'learning_rate': 0.04469412974613522, 'subsample': 0.7698190202535963, 'colsample_bytree': 0.5497039276510726}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:16:02,463]\u001b[0m Trial 63 finished with value: 0.5746090058990163 and parameters: {'n_estimators': 304, 'max_depth': 62, 'learning_rate': 0.2478940513601265, 'subsample': 0.8485398562135344, 'colsample_bytree': 0.5356403391885195}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:16:41,022]\u001b[0m Trial 64 finished with value: 0.5919837414683649 and parameters: {'n_estimators': 426, 'max_depth': 55, 'learning_rate': 0.019681502394186846, 'subsample': 0.4597691741210883, 'colsample_bytree': 0.5823494472787523}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:17:18,514]\u001b[0m Trial 65 finished with value: 0.5917707231582465 and parameters: {'n_estimators': 370, 'max_depth': 42, 'learning_rate': 0.05077954342793696, 'subsample': 0.6463184275828932, 'colsample_bytree': 0.9180049097926369}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:17:35,330]\u001b[0m Trial 66 finished with value: 0.5910043165293739 and parameters: {'n_estimators': 167, 'max_depth': 59, 'learning_rate': 0.03247867378382238, 'subsample': 0.7004214878032259, 'colsample_bytree': 0.5130807237269497}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:18:13,780]\u001b[0m Trial 67 finished with value: 0.5904916320060434 and parameters: {'n_estimators': 719, 'max_depth': 48, 'learning_rate': 0.06033573891926266, 'subsample': 0.9540875176436534, 'colsample_bytree': 0.4368989113066697}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:18:34,069]\u001b[0m Trial 68 finished with value: 0.5924018978393736 and parameters: {'n_estimators': 242, 'max_depth': 91, 'learning_rate': 0.07606206860015177, 'subsample': 0.2354915971847734, 'colsample_bytree': 0.6505305480365309}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:18:55,380]\u001b[0m Trial 69 finished with value: 0.5931271174150371 and parameters: {'n_estimators': 278, 'max_depth': 67, 'learning_rate': 0.040293595011565805, 'subsample': 0.3651627313310938, 'colsample_bytree': 0.4711931215318473}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:19:07,401]\u001b[0m Trial 70 finished with value: 0.5866880417386997 and parameters: {'n_estimators': 117, 'max_depth': 67, 'learning_rate': 0.018007080714009492, 'subsample': 0.35378634549569876, 'colsample_bytree': 0.40330230315806515}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:19:29,582]\u001b[0m Trial 71 finished with value: 0.5910962448300039 and parameters: {'n_estimators': 292, 'max_depth': 64, 'learning_rate': 0.03982138965788446, 'subsample': 0.41908678013499756, 'colsample_bytree': 0.473687810371148}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:19:54,606]\u001b[0m Trial 72 finished with value: 0.5922207415892771 and parameters: {'n_estimators': 332, 'max_depth': 58, 'learning_rate': 0.05089425832291539, 'subsample': 0.2018041231755393, 'colsample_bytree': 0.5601272915284659}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:20:29,727]\u001b[0m Trial 73 finished with value: 0.5929030191264066 and parameters: {'n_estimators': 503, 'max_depth': 70, 'learning_rate': 0.026288369837379012, 'subsample': 0.334979516180565, 'colsample_bytree': 0.4443526812573769}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:21:14,856]\u001b[0m Trial 74 finished with value: 0.5925382407583437 and parameters: {'n_estimators': 587, 'max_depth': 70, 'learning_rate': 0.010056428813305124, 'subsample': 0.3372655857172147, 'colsample_bytree': 0.37689324958070175}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:21:52,848]\u001b[0m Trial 75 finished with value: 0.593304564207553 and parameters: {'n_estimators': 650, 'max_depth': 76, 'learning_rate': 0.023405479937706322, 'subsample': 0.3775468256976457, 'colsample_bytree': 0.3351997191295458}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:22:23,651]\u001b[0m Trial 76 finished with value: 0.594191129272265 and parameters: {'n_estimators': 671, 'max_depth': 81, 'learning_rate': 0.02597538912796879, 'subsample': 0.38799790113707955, 'colsample_bytree': 0.2007863534801912}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:22:54,538]\u001b[0m Trial 77 finished with value: 0.5930588889054762 and parameters: {'n_estimators': 646, 'max_depth': 81, 'learning_rate': 0.030009471815863675, 'subsample': 0.3841528004498884, 'colsample_bytree': 0.23388398960638096}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:23:24,461]\u001b[0m Trial 78 finished with value: 0.5941619318558892 and parameters: {'n_estimators': 670, 'max_depth': 85, 'learning_rate': 0.030120715137138144, 'subsample': 0.38817259690347755, 'colsample_bytree': 0.20135255655124135}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:24:02,632]\u001b[0m Trial 79 finished with value: 0.5946013672844815 and parameters: {'n_estimators': 694, 'max_depth': 86, 'learning_rate': 0.0195204431664913, 'subsample': 0.28857900041440604, 'colsample_bytree': 0.2776936578650241}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:24:41,651]\u001b[0m Trial 80 finished with value: 0.5927259192158407 and parameters: {'n_estimators': 691, 'max_depth': 76, 'learning_rate': 0.01738843552323308, 'subsample': 0.279162436768142, 'colsample_bytree': 0.2751940664768812}. Best is trial 27 with value: 0.5949157150158333.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:25:15,686]\u001b[0m Trial 81 finished with value: 0.595494332412956 and parameters: {'n_estimators': 760, 'max_depth': 85, 'learning_rate': 0.02935086260767057, 'subsample': 0.3792225838646886, 'colsample_bytree': 0.21433910546560286}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:25:52,103]\u001b[0m Trial 82 finished with value: 0.5939011502602921 and parameters: {'n_estimators': 789, 'max_depth': 84, 'learning_rate': 0.025540950212464022, 'subsample': 0.3089105729170341, 'colsample_bytree': 0.21588411042168348}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:26:28,280]\u001b[0m Trial 83 finished with value: 0.5938393691473856 and parameters: {'n_estimators': 782, 'max_depth': 86, 'learning_rate': 0.02641609663017136, 'subsample': 0.30626415528791484, 'colsample_bytree': 0.2166125066413228}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:27:04,685]\u001b[0m Trial 84 finished with value: 0.5933679348704433 and parameters: {'n_estimators': 784, 'max_depth': 86, 'learning_rate': 0.02560637827653592, 'subsample': 0.2585419171526662, 'colsample_bytree': 0.21375747603208803}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:27:40,743]\u001b[0m Trial 85 finished with value: 0.593484223760074 and parameters: {'n_estimators': 814, 'max_depth': 95, 'learning_rate': 0.027745779832580354, 'subsample': 0.2520732188044093, 'colsample_bytree': 0.20722074152666461}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:28:25,625]\u001b[0m Trial 86 finished with value: 0.5928958854109521 and parameters: {'n_estimators': 894, 'max_depth': 97, 'learning_rate': 0.015509647405457763, 'subsample': 0.25114511965365033, 'colsample_bytree': 0.22061461965900092}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:29:05,377]\u001b[0m Trial 87 finished with value: 0.594937918542097 and parameters: {'n_estimators': 803, 'max_depth': 85, 'learning_rate': 0.029211060315886134, 'subsample': 0.25742676806962034, 'colsample_bytree': 0.2818819550105705}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:29:47,395]\u001b[0m Trial 88 finished with value: 0.5933894146339147 and parameters: {'n_estimators': 869, 'max_depth': 93, 'learning_rate': 0.030435905788670402, 'subsample': 0.22939461940399722, 'colsample_bytree': 0.2811425473675202}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:30:19,124]\u001b[0m Trial 89 finished with value: 0.5921468107731251 and parameters: {'n_estimators': 752, 'max_depth': 100, 'learning_rate': 0.05441813659373514, 'subsample': 0.31536721993483774, 'colsample_bytree': 0.24310400891403672}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:31:00,281]\u001b[0m Trial 90 finished with value: 0.5942327011236215 and parameters: {'n_estimators': 744, 'max_depth': 94, 'learning_rate': 0.015247784234120182, 'subsample': 0.2973686631832416, 'colsample_bytree': 0.2655047894040494}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:31:41,338]\u001b[0m Trial 91 finished with value: 0.5929709910060879 and parameters: {'n_estimators': 733, 'max_depth': 84, 'learning_rate': 0.01467867575032436, 'subsample': 0.2984073164504304, 'colsample_bytree': 0.26737163550374643}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:32:20,521]\u001b[0m Trial 92 finished with value: 0.5940602955884234 and parameters: {'n_estimators': 787, 'max_depth': 94, 'learning_rate': 0.0315598460612848, 'subsample': 0.330952110770888, 'colsample_bytree': 0.29227652820636457}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:32:58,823]\u001b[0m Trial 93 finished with value: 0.5935893269219568 and parameters: {'n_estimators': 777, 'max_depth': 91, 'learning_rate': 0.03299187226714369, 'subsample': 0.3308898702440956, 'colsample_bytree': 0.2965294217840993}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:33:35,003]\u001b[0m Trial 94 finished with value: 0.5939013155339795 and parameters: {'n_estimators': 701, 'max_depth': 88, 'learning_rate': 0.019328345521769666, 'subsample': 0.29453473862950175, 'colsample_bytree': 0.24576952101165944}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:34:12,149]\u001b[0m Trial 95 finished with value: 0.5942475594546934 and parameters: {'n_estimators': 680, 'max_depth': 88, 'learning_rate': 0.018684174435202986, 'subsample': 0.27759276120216053, 'colsample_bytree': 0.25121010929334836}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:34:56,102]\u001b[0m Trial 96 finished with value: 0.5927932606467885 and parameters: {'n_estimators': 689, 'max_depth': 88, 'learning_rate': 0.01118722437267583, 'subsample': 0.2684974906543122, 'colsample_bytree': 0.3093332208085568}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:35:26,016]\u001b[0m Trial 97 finished with value: 0.5917357866711597 and parameters: {'n_estimators': 683, 'max_depth': 93, 'learning_rate': 0.04607912025591332, 'subsample': 0.28969641301516774, 'colsample_bytree': 0.24986567985340713}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:36:04,104]\u001b[0m Trial 98 finished with value: 0.5929348816187844 and parameters: {'n_estimators': 618, 'max_depth': 81, 'learning_rate': 0.01889050760550032, 'subsample': 0.3893396769045166, 'colsample_bytree': 0.34981888560101954}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:36:38,206]\u001b[0m Trial 99 finished with value: 0.5941465391793088 and parameters: {'n_estimators': 719, 'max_depth': 90, 'learning_rate': 0.03339728738286944, 'subsample': 0.3280120591916189, 'colsample_bytree': 0.2620951214217309}. Best is trial 81 with value: 0.595494332412956.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best F1 score: 0.595494332412956\n",
            "Best hyperparameters: {'n_estimators': 760, 'max_depth': 85, 'learning_rate': 0.02935086260767057, 'subsample': 0.3792225838646886, 'colsample_bytree': 0.21433910546560286}\n"
          ]
        }
      ],
      "source": [
        "def objective_LightGBM(trial):\n",
        "      n_estimators_values = trial.suggest_int('n_estimators', 10, 1000)\n",
        "      max_depth_values = trial.suggest_int('max_depth', 1, 100)\n",
        "      learning_rate_values = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
        "      subsample_values = trial.suggest_float('subsample', 0.2, 1)\n",
        "      colsample_bytree_values = trial.suggest_float('colsample_bytree', 0.2, 1)\n",
        "      clf = LGBMClassifier(scale_pos_weight=scale_pos_weight_data, \n",
        "                          n_estimators=n_estimators_values,\n",
        "                          max_depth=max_depth_values,\n",
        "                          learning_rate=learning_rate_values,\n",
        "                          subsample=subsample_values,\n",
        "                          colsample_bytree=colsample_bytree_values)\n",
        "      model_f1scores = cross_val_score(estimator = clf, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "      return model_f1scores.mean()\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective_LightGBM, n_trials=100)\n",
        "\n",
        "trial = study.best_trial\n",
        "print('Best F1 score: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2: Hyperparameter tuning for XGBoost is skipped since it is time consuming"
      ],
      "metadata": {
        "id": "HxDt_h3e6FiN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6YknVGl6Acl"
      },
      "source": [
        "### 3: Hyperparameter tuning for LightGBM + XGBoost (Soft Voting)\n",
        "\n",
        "(tune most hyperparameters of LightGBM except scale_pos_weight(which is given the same value as before))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d460ec-b90a-4972-d05d-a01d08aeba3f",
        "id": "JrqG21cl6Ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-12-10 06:36:40,141]\u001b[0m A new study created in memory with name: no-name-4a1b40ce-6333-4e32-a11e-1ecb5128ea2a\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:37:14,073]\u001b[0m Trial 0 finished with value: 0.5828185493519413 and parameters: {'n_estimators': 411, 'max_depth': 46, 'learning_rate': 0.13076747679294923, 'subsample': 0.4085950844309596, 'colsample_bytree': 0.8629935395210719}. Best is trial 0 with value: 0.5828185493519413.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:37:32,336]\u001b[0m Trial 1 finished with value: 0.5796852515400689 and parameters: {'n_estimators': 453, 'max_depth': 86, 'learning_rate': 0.1806719947440587, 'subsample': 0.20457680719172658, 'colsample_bytree': 0.23884414728756811}. Best is trial 0 with value: 0.5828185493519413.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:38:45,633]\u001b[0m Trial 2 finished with value: 0.5846899721743519 and parameters: {'n_estimators': 843, 'max_depth': 82, 'learning_rate': 0.06609221478286383, 'subsample': 0.8438507748203137, 'colsample_bytree': 0.9767910810545337}. Best is trial 2 with value: 0.5846899721743519.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:39:17,992]\u001b[0m Trial 3 finished with value: 0.5742897074352009 and parameters: {'n_estimators': 745, 'max_depth': 59, 'learning_rate': 0.1503515817972711, 'subsample': 0.9018007817916855, 'colsample_bytree': 0.3323007535761329}. Best is trial 2 with value: 0.5846899721743519.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:40:51,823]\u001b[0m Trial 4 finished with value: 0.5901119671478442 and parameters: {'n_estimators': 966, 'max_depth': 49, 'learning_rate': 0.027493233050873825, 'subsample': 0.28976594007838674, 'colsample_bytree': 0.9983137565079716}. Best is trial 4 with value: 0.5901119671478442.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:41:21,001]\u001b[0m Trial 5 finished with value: 0.5633551868074026 and parameters: {'n_estimators': 538, 'max_depth': 21, 'learning_rate': 0.2520428044797872, 'subsample': 0.6461229927447284, 'colsample_bytree': 0.5146527264547034}. Best is trial 4 with value: 0.5901119671478442.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:41:39,375]\u001b[0m Trial 6 finished with value: 0.5799272404674332 and parameters: {'n_estimators': 271, 'max_depth': 66, 'learning_rate': 0.20751294685588947, 'subsample': 0.3615441627815864, 'colsample_bytree': 0.6080186556637456}. Best is trial 4 with value: 0.5901119671478442.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:41:49,475]\u001b[0m Trial 7 finished with value: 0.5869462091330158 and parameters: {'n_estimators': 149, 'max_depth': 17, 'learning_rate': 0.18580951647500404, 'subsample': 0.40153248518536877, 'colsample_bytree': 0.4279713248329289}. Best is trial 4 with value: 0.5901119671478442.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:42:59,034]\u001b[0m Trial 8 finished with value: 0.5729093519755253 and parameters: {'n_estimators': 918, 'max_depth': 84, 'learning_rate': 0.13690743419108262, 'subsample': 0.5269832959138863, 'colsample_bytree': 0.890844203539497}. Best is trial 4 with value: 0.5901119671478442.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:43:19,023]\u001b[0m Trial 9 finished with value: 0.5784054546697107 and parameters: {'n_estimators': 394, 'max_depth': 66, 'learning_rate': 0.1838750682728337, 'subsample': 0.4718062184676146, 'colsample_bytree': 0.4161286338784222}. Best is trial 4 with value: 0.5901119671478442.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:44:26,493]\u001b[0m Trial 10 finished with value: 0.5914882705902003 and parameters: {'n_estimators': 693, 'max_depth': 37, 'learning_rate': 0.013042490863696852, 'subsample': 0.20458524047264798, 'colsample_bytree': 0.7013745023409265}. Best is trial 10 with value: 0.5914882705902003.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:45:34,347]\u001b[0m Trial 11 finished with value: 0.5928696305435139 and parameters: {'n_estimators': 662, 'max_depth': 35, 'learning_rate': 0.012025210187646275, 'subsample': 0.24308596328208226, 'colsample_bytree': 0.7117236721506904}. Best is trial 11 with value: 0.5928696305435139.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:46:30,946]\u001b[0m Trial 12 finished with value: 0.5929552374310545 and parameters: {'n_estimators': 652, 'max_depth': 36, 'learning_rate': 0.02152923661620477, 'subsample': 0.2016373099300561, 'colsample_bytree': 0.6974850257351487}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:46:51,874]\u001b[0m Trial 13 finished with value: 0.586635383164431 and parameters: {'n_estimators': 597, 'max_depth': 1, 'learning_rate': 0.0763528147592511, 'subsample': 0.5909144221085694, 'colsample_bytree': 0.7326445976696716}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:47:38,380]\u001b[0m Trial 14 finished with value: 0.5860152230740024 and parameters: {'n_estimators': 654, 'max_depth': 32, 'learning_rate': 0.07589499641787174, 'subsample': 0.7077342162029188, 'colsample_bytree': 0.7225688991675212}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:48:32,020]\u001b[0m Trial 15 finished with value: 0.5908698845367224 and parameters: {'n_estimators': 808, 'max_depth': 24, 'learning_rate': 0.04418254985902187, 'subsample': 0.29857214788220066, 'colsample_bytree': 0.6101038759666044}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:48:39,356]\u001b[0m Trial 16 finished with value: 0.5891553146467129 and parameters: {'n_estimators': 43, 'max_depth': 7, 'learning_rate': 0.10523242274814298, 'subsample': 0.29382311413217366, 'colsample_bytree': 0.8197966063831397}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:49:17,470]\u001b[0m Trial 17 finished with value: 0.5924065183082728 and parameters: {'n_estimators': 572, 'max_depth': 100, 'learning_rate': 0.043361276717054774, 'subsample': 0.7761299677977229, 'colsample_bytree': 0.5389294105238078}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:49:41,348]\u001b[0m Trial 18 finished with value: 0.5686694600752642 and parameters: {'n_estimators': 315, 'max_depth': 36, 'learning_rate': 0.2751376618022289, 'subsample': 0.9797624612347864, 'colsample_bytree': 0.7951820034299462}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:50:30,154]\u001b[0m Trial 19 finished with value: 0.5835998593694315 and parameters: {'n_estimators': 745, 'max_depth': 43, 'learning_rate': 0.10342755027060586, 'subsample': 0.4889824178925607, 'colsample_bytree': 0.6718067131377283}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:51:26,219]\u001b[0m Trial 20 finished with value: 0.5921609144547081 and parameters: {'n_estimators': 647, 'max_depth': 56, 'learning_rate': 0.010948351884173264, 'subsample': 0.26620355382641936, 'colsample_bytree': 0.511879293444715}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:52:02,201]\u001b[0m Trial 21 finished with value: 0.5917842100791819 and parameters: {'n_estimators': 535, 'max_depth': 74, 'learning_rate': 0.04322898639754917, 'subsample': 0.7823493599786709, 'colsample_bytree': 0.5316371335974894}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:52:41,106]\u001b[0m Trial 22 finished with value: 0.5905591189244563 and parameters: {'n_estimators': 523, 'max_depth': 30, 'learning_rate': 0.04946181398136737, 'subsample': 0.7150936642573789, 'colsample_bytree': 0.6491582424486301}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:53:17,201]\u001b[0m Trial 23 finished with value: 0.5841814037334652 and parameters: {'n_estimators': 601, 'max_depth': 99, 'learning_rate': 0.09784383495514945, 'subsample': 0.7940478226341258, 'colsample_bytree': 0.5570882379482636}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:54:05,068]\u001b[0m Trial 24 finished with value: 0.5923020214631369 and parameters: {'n_estimators': 771, 'max_depth': 96, 'learning_rate': 0.03095390506233847, 'subsample': 0.5643421516354301, 'colsample_bytree': 0.4624882976762337}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:55:07,150]\u001b[0m Trial 25 finished with value: 0.5857857180276819 and parameters: {'n_estimators': 844, 'max_depth': 42, 'learning_rate': 0.06383030542420293, 'subsample': 0.37294394249591384, 'colsample_bytree': 0.75795982727798}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:55:50,936]\u001b[0m Trial 26 finished with value: 0.5916587909031537 and parameters: {'n_estimators': 601, 'max_depth': 12, 'learning_rate': 0.010356252072802698, 'subsample': 0.6438638695117294, 'colsample_bytree': 0.3565774226517752}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:56:22,578]\u001b[0m Trial 27 finished with value: 0.5872855183664583 and parameters: {'n_estimators': 461, 'max_depth': 25, 'learning_rate': 0.08756554912287803, 'subsample': 0.9843215064436197, 'colsample_bytree': 0.6418998220301441}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:57:07,631]\u001b[0m Trial 28 finished with value: 0.5904771167511026 and parameters: {'n_estimators': 688, 'max_depth': 55, 'learning_rate': 0.054801780799117156, 'subsample': 0.2479583343140019, 'colsample_bytree': 0.5837072763334344}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:57:39,011]\u001b[0m Trial 29 finished with value: 0.5839277460964536 and parameters: {'n_estimators': 381, 'max_depth': 46, 'learning_rate': 0.12163923423934686, 'subsample': 0.4357321302684479, 'colsample_bytree': 0.8402638782594324}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:58:17,991]\u001b[0m Trial 30 finished with value: 0.592260116662929 and parameters: {'n_estimators': 322, 'max_depth': 67, 'learning_rate': 0.0251965940913693, 'subsample': 0.3381079240032005, 'colsample_bytree': 0.8783995725817341}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:59:02,821]\u001b[0m Trial 31 finished with value: 0.5911404867048858 and parameters: {'n_estimators': 752, 'max_depth': 97, 'learning_rate': 0.035931870863174765, 'subsample': 0.5565887477799288, 'colsample_bytree': 0.4542113056961664}. Best is trial 12 with value: 0.5929552374310545.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 06:59:54,423]\u001b[0m Trial 32 finished with value: 0.5934127654293612 and parameters: {'n_estimators': 804, 'max_depth': 94, 'learning_rate': 0.02929070500549233, 'subsample': 0.20512368881853218, 'colsample_bytree': 0.49202445974850934}. Best is trial 32 with value: 0.5934127654293612.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:00:31,489]\u001b[0m Trial 33 finished with value: 0.5910236126584414 and parameters: {'n_estimators': 876, 'max_depth': 77, 'learning_rate': 0.05837091359709341, 'subsample': 0.2482068565618515, 'colsample_bytree': 0.2677816841049423}. Best is trial 32 with value: 0.5934127654293612.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:01:16,319]\u001b[0m Trial 34 finished with value: 0.5933576829806163 and parameters: {'n_estimators': 457, 'max_depth': 91, 'learning_rate': 0.027612886859531748, 'subsample': 0.20964476641519678, 'colsample_bytree': 0.7745001413963143}. Best is trial 32 with value: 0.5934127654293612.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:02:08,371]\u001b[0m Trial 35 finished with value: 0.5909162497779701 and parameters: {'n_estimators': 454, 'max_depth': 89, 'learning_rate': 0.023170134966796877, 'subsample': 0.21300157359197291, 'colsample_bytree': 0.9349722858399434}. Best is trial 32 with value: 0.5934127654293612.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:03:01,884]\u001b[0m Trial 36 finished with value: 0.5858443091944415 and parameters: {'n_estimators': 690, 'max_depth': 91, 'learning_rate': 0.0736380239576534, 'subsample': 0.33317064426927506, 'colsample_bytree': 0.7766624799390859}. Best is trial 32 with value: 0.5934127654293612.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:04:16,176]\u001b[0m Trial 37 finished with value: 0.5914555302473644 and parameters: {'n_estimators': 977, 'max_depth': 77, 'learning_rate': 0.028218993835865198, 'subsample': 0.200060336915898, 'colsample_bytree': 0.6835247500342233}. Best is trial 32 with value: 0.5934127654293612.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:05:16,388]\u001b[0m Trial 38 finished with value: 0.551809307272005 and parameters: {'n_estimators': 900, 'max_depth': 50, 'learning_rate': 0.23967864822479712, 'subsample': 0.31557651168487083, 'colsample_bytree': 0.7568462110961091}. Best is trial 32 with value: 0.5934127654293612.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:06:20,871]\u001b[0m Trial 39 finished with value: 0.5750198765553978 and parameters: {'n_estimators': 801, 'max_depth': 91, 'learning_rate': 0.1202134010329068, 'subsample': 0.24872975524589314, 'colsample_bytree': 0.936278941671694}. Best is trial 32 with value: 0.5934127654293612.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:06:35,393]\u001b[0m Trial 40 finished with value: 0.5867865342954406 and parameters: {'n_estimators': 186, 'max_depth': 61, 'learning_rate': 0.15789545365257224, 'subsample': 0.38911257157778645, 'colsample_bytree': 0.6102486368407768}. Best is trial 32 with value: 0.5934127654293612.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:07:15,823]\u001b[0m Trial 41 finished with value: 0.5924629553903707 and parameters: {'n_estimators': 564, 'max_depth': 84, 'learning_rate': 0.03928715284190343, 'subsample': 0.9082929888678701, 'colsample_bytree': 0.5657246738908822}. Best is trial 32 with value: 0.5934127654293612.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:08:01,883]\u001b[0m Trial 42 finished with value: 0.5938480671661294 and parameters: {'n_estimators': 648, 'max_depth': 82, 'learning_rate': 0.022947615103110653, 'subsample': 0.8936521934197924, 'colsample_bytree': 0.48520042148318576}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:08:41,874]\u001b[0m Trial 43 finished with value: 0.5933297967642495 and parameters: {'n_estimators': 493, 'max_depth': 80, 'learning_rate': 0.017883559372200052, 'subsample': 0.23292787251263927, 'colsample_bytree': 0.4888571620585778}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:09:08,815]\u001b[0m Trial 44 finished with value: 0.5925839589687877 and parameters: {'n_estimators': 489, 'max_depth': 80, 'learning_rate': 0.062140352806578356, 'subsample': 0.20450507647406654, 'colsample_bytree': 0.3769886146133932}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:09:40,649]\u001b[0m Trial 45 finished with value: 0.5935939086253168 and parameters: {'n_estimators': 433, 'max_depth': 70, 'learning_rate': 0.025725799559791603, 'subsample': 0.43022308890501887, 'colsample_bytree': 0.45257482181898295}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:10:02,974]\u001b[0m Trial 46 finished with value: 0.5733612988592898 and parameters: {'n_estimators': 411, 'max_depth': 70, 'learning_rate': 0.21226638348095597, 'subsample': 0.44215144068276435, 'colsample_bytree': 0.47659804145483886}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:10:21,536]\u001b[0m Trial 47 finished with value: 0.5906310397956653 and parameters: {'n_estimators': 361, 'max_depth': 87, 'learning_rate': 0.08997928682448744, 'subsample': 0.28008870823743537, 'colsample_bytree': 0.3170979102618996}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:10:42,568]\u001b[0m Trial 48 finished with value: 0.5921924647488122 and parameters: {'n_estimators': 251, 'max_depth': 94, 'learning_rate': 0.023316983712899343, 'subsample': 0.34742378615210234, 'colsample_bytree': 0.41200559109507484}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:11:13,492]\u001b[0m Trial 49 finished with value: 0.5912975749844482 and parameters: {'n_estimators': 488, 'max_depth': 81, 'learning_rate': 0.05312689363159359, 'subsample': 0.9093706905164253, 'colsample_bytree': 0.49840360908560716}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:11:37,617]\u001b[0m Trial 50 finished with value: 0.5894181431453946 and parameters: {'n_estimators': 418, 'max_depth': 74, 'learning_rate': 0.07482984292371905, 'subsample': 0.5130273446166028, 'colsample_bytree': 0.42845843366700415}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:12:17,279]\u001b[0m Trial 51 finished with value: 0.5931764362824916 and parameters: {'n_estimators': 635, 'max_depth': 86, 'learning_rate': 0.0221594947610918, 'subsample': 0.23932740112819711, 'colsample_bytree': 0.3899452851874943}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:12:45,498]\u001b[0m Trial 52 finished with value: 0.5938387463444861 and parameters: {'n_estimators': 435, 'max_depth': 86, 'learning_rate': 0.03373313449636346, 'subsample': 0.2815252195831328, 'colsample_bytree': 0.3975219773845396}. Best is trial 42 with value: 0.5938480671661294.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:13:06,427]\u001b[0m Trial 53 finished with value: 0.5947545441579575 and parameters: {'n_estimators': 342, 'max_depth': 94, 'learning_rate': 0.04019159747958304, 'subsample': 0.30822388096644604, 'colsample_bytree': 0.3236223029454798}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:13:24,979]\u001b[0m Trial 54 finished with value: 0.5932296767886756 and parameters: {'n_estimators': 340, 'max_depth': 93, 'learning_rate': 0.033601447203755866, 'subsample': 0.4154715255287895, 'colsample_bytree': 0.21763288423474267}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:13:41,845]\u001b[0m Trial 55 finished with value: 0.5937337355565853 and parameters: {'n_estimators': 271, 'max_depth': 87, 'learning_rate': 0.047593675189707516, 'subsample': 0.310728940191462, 'colsample_bytree': 0.2943503728966968}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:13:58,920]\u001b[0m Trial 56 finished with value: 0.5937884172518526 and parameters: {'n_estimators': 278, 'max_depth': 85, 'learning_rate': 0.0466593646335861, 'subsample': 0.3104429075090306, 'colsample_bytree': 0.31248596433584297}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:14:15,216]\u001b[0m Trial 57 finished with value: 0.5932319185668865 and parameters: {'n_estimators': 256, 'max_depth': 85, 'learning_rate': 0.04695862661432264, 'subsample': 0.3132186457696995, 'colsample_bytree': 0.2982709501992128}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:14:27,230]\u001b[0m Trial 58 finished with value: 0.5922250171606989 and parameters: {'n_estimators': 196, 'max_depth': 69, 'learning_rate': 0.06801235387376806, 'subsample': 0.38226762392980795, 'colsample_bytree': 0.2637290475152665}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:14:35,699]\u001b[0m Trial 59 finished with value: 0.5913176018118274 and parameters: {'n_estimators': 95, 'max_depth': 72, 'learning_rate': 0.08425653460574534, 'subsample': 0.28293530700159725, 'colsample_bytree': 0.35056856893012917}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:14:49,929]\u001b[0m Trial 60 finished with value: 0.5858090830600212 and parameters: {'n_estimators': 290, 'max_depth': 77, 'learning_rate': 0.16077552427684305, 'subsample': 0.365938661875454, 'colsample_bytree': 0.3059449536379399}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:15:08,020]\u001b[0m Trial 61 finished with value: 0.5935090295435834 and parameters: {'n_estimators': 298, 'max_depth': 88, 'learning_rate': 0.038908372981402, 'subsample': 0.46060421413962704, 'colsample_bytree': 0.28095031347113303}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:15:23,113]\u001b[0m Trial 62 finished with value: 0.5930490461362934 and parameters: {'n_estimators': 234, 'max_depth': 63, 'learning_rate': 0.0403692137802617, 'subsample': 0.4692139310199981, 'colsample_bytree': 0.26628420415757553}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:15:41,580]\u001b[0m Trial 63 finished with value: 0.5944591194834453 and parameters: {'n_estimators': 297, 'max_depth': 83, 'learning_rate': 0.051619820713190864, 'subsample': 0.41589504389812215, 'colsample_bytree': 0.33954213445116505}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:16:02,360]\u001b[0m Trial 64 finished with value: 0.5928618236311238 and parameters: {'n_estimators': 353, 'max_depth': 83, 'learning_rate': 0.0518460417234112, 'subsample': 0.41715530847497545, 'colsample_bytree': 0.33767998717354436}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:16:14,472]\u001b[0m Trial 65 finished with value: 0.5940285339171133 and parameters: {'n_estimators': 215, 'max_depth': 78, 'learning_rate': 0.06489088225872078, 'subsample': 0.3064313630017998, 'colsample_bytree': 0.2263906917273287}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:16:26,573]\u001b[0m Trial 66 finished with value: 0.5926725975707525 and parameters: {'n_estimators': 218, 'max_depth': 98, 'learning_rate': 0.05883612572047766, 'subsample': 0.31576302437273246, 'colsample_bytree': 0.20603992108018}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:16:36,156]\u001b[0m Trial 67 finished with value: 0.5920688754166987 and parameters: {'n_estimators': 140, 'max_depth': 79, 'learning_rate': 0.06667460378927309, 'subsample': 0.3488436145794322, 'colsample_bytree': 0.24287784386216896}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:16:47,549]\u001b[0m Trial 68 finished with value: 0.5925897541746308 and parameters: {'n_estimators': 156, 'max_depth': 83, 'learning_rate': 0.08326904858817039, 'subsample': 0.8588349740746404, 'colsample_bytree': 0.37439935242491934}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:17:05,025]\u001b[0m Trial 69 finished with value: 0.5930331121926183 and parameters: {'n_estimators': 277, 'max_depth': 88, 'learning_rate': 0.04790475876578323, 'subsample': 0.27748325033037213, 'colsample_bytree': 0.32576269491932874}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:17:19,929]\u001b[0m Trial 70 finished with value: 0.590972372450743 and parameters: {'n_estimators': 327, 'max_depth': 74, 'learning_rate': 0.11281155707208132, 'subsample': 0.30332205187866734, 'colsample_bytree': 0.2407436638088216}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:17:53,793]\u001b[0m Trial 71 finished with value: 0.5905777630357326 and parameters: {'n_estimators': 381, 'max_depth': 85, 'learning_rate': 0.010310443074634041, 'subsample': 0.6885811267962021, 'colsample_bytree': 0.44308386173612135}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:18:16,087]\u001b[0m Trial 72 finished with value: 0.5930519274369744 and parameters: {'n_estimators': 307, 'max_depth': 77, 'learning_rate': 0.033989129464652296, 'subsample': 0.39796902037865356, 'colsample_bytree': 0.40785020292128527}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:18:38,542]\u001b[0m Trial 73 finished with value: 0.5931049440748917 and parameters: {'n_estimators': 429, 'max_depth': 91, 'learning_rate': 0.04506807246547851, 'subsample': 0.3291277271631623, 'colsample_bytree': 0.2902801035769665}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:19:00,276]\u001b[0m Trial 74 finished with value: 0.5928940638058907 and parameters: {'n_estimators': 385, 'max_depth': 96, 'learning_rate': 0.057109986286994215, 'subsample': 0.27003602825958434, 'colsample_bytree': 0.36682212182613627}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:19:17,491]\u001b[0m Trial 75 finished with value: 0.5901385233914678 and parameters: {'n_estimators': 210, 'max_depth': 82, 'learning_rate': 0.017592449511567562, 'subsample': 0.5042350386505914, 'colsample_bytree': 0.34071304305560207}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:19:29,885]\u001b[0m Trial 76 finished with value: 0.5919235047936394 and parameters: {'n_estimators': 168, 'max_depth': 64, 'learning_rate': 0.06939178427480608, 'subsample': 0.3597839349510628, 'colsample_bytree': 0.3888061105398479}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:19:48,076]\u001b[0m Trial 77 finished with value: 0.5931360916817906 and parameters: {'n_estimators': 269, 'max_depth': 89, 'learning_rate': 0.033939917441992325, 'subsample': 0.5423163463311507, 'colsample_bytree': 0.32010384941344705}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:19:55,409]\u001b[0m Trial 78 finished with value: 0.5741074326615755 and parameters: {'n_estimators': 84, 'max_depth': 71, 'learning_rate': 0.016288526415952714, 'subsample': 0.3312559616201375, 'colsample_bytree': 0.22343745655758002}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:20:04,519]\u001b[0m Trial 79 finished with value: 0.5902596593852436 and parameters: {'n_estimators': 120, 'max_depth': 100, 'learning_rate': 0.1462726557214082, 'subsample': 0.6295182817847077, 'colsample_bytree': 0.4306016738282241}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:20:27,732]\u001b[0m Trial 80 finished with value: 0.5877261400082168 and parameters: {'n_estimators': 431, 'max_depth': 94, 'learning_rate': 0.09437594595503224, 'subsample': 0.9535205428791393, 'colsample_bytree': 0.3993211136596897}. Best is trial 53 with value: 0.5947545441579575.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:20:45,892]\u001b[0m Trial 81 finished with value: 0.595012419877925 and parameters: {'n_estimators': 300, 'max_depth': 79, 'learning_rate': 0.04208439247743048, 'subsample': 0.4377450353973782, 'colsample_bytree': 0.2970209187817083}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:21:00,318]\u001b[0m Trial 82 finished with value: 0.5937062977902877 and parameters: {'n_estimators': 233, 'max_depth': 75, 'learning_rate': 0.05088411231777071, 'subsample': 0.29343945846674957, 'colsample_bytree': 0.2783106428431077}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:21:14,482]\u001b[0m Trial 83 finished with value: 0.5925471980471049 and parameters: {'n_estimators': 233, 'max_depth': 79, 'learning_rate': 0.05109758456453294, 'subsample': 0.29976647036895976, 'colsample_bytree': 0.25226620000546196}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:21:33,141]\u001b[0m Trial 84 finished with value: 0.5934747371589746 and parameters: {'n_estimators': 365, 'max_depth': 75, 'learning_rate': 0.06244179335212627, 'subsample': 0.5887200976111564, 'colsample_bytree': 0.28574942681974297}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:21:50,241]\u001b[0m Trial 85 finished with value: 0.592239426631929 and parameters: {'n_estimators': 328, 'max_depth': 86, 'learning_rate': 0.07862704874371539, 'subsample': 0.264029302348681, 'colsample_bytree': 0.30201620014228625}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:22:07,728]\u001b[0m Trial 86 finished with value: 0.5919055153433718 and parameters: {'n_estimators': 250, 'max_depth': 81, 'learning_rate': 0.041769750149182126, 'subsample': 0.367444114587416, 'colsample_bytree': 0.356747374126378}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:22:22,631]\u001b[0m Trial 87 finished with value: 0.5930427373898687 and parameters: {'n_estimators': 283, 'max_depth': 91, 'learning_rate': 0.05473178233797846, 'subsample': 0.7579449401436137, 'colsample_bytree': 0.22723606887208622}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:22:36,772]\u001b[0m Trial 88 finished with value: 0.59165588042656 and parameters: {'n_estimators': 178, 'max_depth': 83, 'learning_rate': 0.029931123253481264, 'subsample': 0.2220018369129228, 'colsample_bytree': 0.32967245009672924}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:22:50,467]\u001b[0m Trial 89 finished with value: 0.5925999915146779 and parameters: {'n_estimators': 210, 'max_depth': 75, 'learning_rate': 0.0453292941886427, 'subsample': 0.2591979197060422, 'colsample_bytree': 0.28090391177559115}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:23:12,039]\u001b[0m Trial 90 finished with value: 0.5935551946092558 and parameters: {'n_estimators': 402, 'max_depth': 78, 'learning_rate': 0.03749282409616879, 'subsample': 0.28893745850959496, 'colsample_bytree': 0.26795375856959536}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:23:36,892]\u001b[0m Trial 91 finished with value: 0.593712264374027 and parameters: {'n_estimators': 514, 'max_depth': 57, 'learning_rate': 0.03006893856379638, 'subsample': 0.4290088377153067, 'colsample_bytree': 0.20533154144164828}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:24:04,919]\u001b[0m Trial 92 finished with value: 0.5925491663847079 and parameters: {'n_estimators': 520, 'max_depth': 54, 'learning_rate': 0.018307165108236382, 'subsample': 0.4510525424169648, 'colsample_bytree': 0.20856464311399528}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:24:23,317]\u001b[0m Trial 93 finished with value: 0.5917187821997185 and parameters: {'n_estimators': 311, 'max_depth': 90, 'learning_rate': 0.029262952584191784, 'subsample': 0.39756786226729507, 'colsample_bytree': 0.24752133440415686}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:24:37,486]\u001b[0m Trial 94 finished with value: 0.5916548172279328 and parameters: {'n_estimators': 233, 'max_depth': 68, 'learning_rate': 0.07085328582292005, 'subsample': 0.3150060199131423, 'colsample_bytree': 0.31030219337170606}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:24:58,365]\u001b[0m Trial 95 finished with value: 0.5768733054786498 and parameters: {'n_estimators': 555, 'max_depth': 87, 'learning_rate': 0.17419469897891615, 'subsample': 0.42535669497784667, 'colsample_bytree': 0.226179499130663}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:25:29,406]\u001b[0m Trial 96 finished with value: 0.5896894108842061 and parameters: {'n_estimators': 721, 'max_depth': 59, 'learning_rate': 0.06313137900729691, 'subsample': 0.3463589081435233, 'colsample_bytree': 0.2575523577509806}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:25:50,094]\u001b[0m Trial 97 finished with value: 0.5935199241833772 and parameters: {'n_estimators': 355, 'max_depth': 47, 'learning_rate': 0.04936907523322097, 'subsample': 0.3777005173388207, 'colsample_bytree': 0.3438820279868244}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:26:00,873]\u001b[0m Trial 98 finished with value: 0.5706993859628963 and parameters: {'n_estimators': 264, 'max_depth': 39, 'learning_rate': 0.2940127500706582, 'subsample': 0.23092063590148904, 'colsample_bytree': 0.20130890604400806}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:26:30,972]\u001b[0m Trial 99 finished with value: 0.5933140990163442 and parameters: {'n_estimators': 618, 'max_depth': 93, 'learning_rate': 0.0384393424326138, 'subsample': 0.3313044853869888, 'colsample_bytree': 0.27539464653069395}. Best is trial 81 with value: 0.595012419877925.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best F1 score: 0.595012419877925\n",
            "Best hyperparameters: {'n_estimators': 300, 'max_depth': 79, 'learning_rate': 0.04208439247743048, 'subsample': 0.4377450353973782, 'colsample_bytree': 0.2970209187817083}\n"
          ]
        }
      ],
      "source": [
        "def objective_SoftVoting(trial):\n",
        "      n_estimators_values = trial.suggest_int('n_estimators', 10, 1000)\n",
        "      max_depth_values = trial.suggest_int('max_depth', 1, 100)\n",
        "      learning_rate_values = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
        "      subsample_values = trial.suggest_float('subsample', 0.2, 1)\n",
        "      colsample_bytree_values = trial.suggest_float('colsample_bytree', 0.2, 1)\n",
        "      clf1 = LGBMClassifier(scale_pos_weight=scale_pos_weight_data, \n",
        "                          n_estimators=n_estimators_values,\n",
        "                          max_depth=max_depth_values,\n",
        "                          learning_rate=learning_rate_values,\n",
        "                          subsample=subsample_values,\n",
        "                          colsample_bytree=colsample_bytree_values)\n",
        "      clf2 = XGBClassifier(scale_pos_weight=scale_pos_weight_data)\n",
        "      estimators=[]\n",
        "      estimators.append(('lgbm', clf1))\n",
        "      estimators.append(('xgb', clf2))\n",
        "      clf = VotingClassifier(estimators, voting='soft')\n",
        "      model_f1scores = cross_val_score(estimator = clf, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "      return model_f1scores.mean()\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective_LightGBM, n_trials=100)\n",
        "\n",
        "trial = study.best_trial\n",
        "print('Best F1 score: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvuwxUfs9xcv"
      },
      "source": [
        "### 4: Hyperparameter tuning for LightGBM + XGBoost (Hard Voting)\n",
        "\n",
        "(tune most hyperparameters of LightGBM except scale_pos_weight(which is given the same value as before))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b1c33c-05ad-414a-8f8f-402d080165e5",
        "id": "3ts-KDrY9xc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-12-10 07:26:31,002]\u001b[0m A new study created in memory with name: no-name-3d69b552-d57d-4979-9e23-94faab26cf8d\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:26:41,341]\u001b[0m Trial 0 finished with value: 0.5876234289654728 and parameters: {'n_estimators': 308, 'max_depth': 1, 'learning_rate': 0.205392081988844, 'subsample': 0.34403720302237994, 'colsample_bytree': 0.5304395478487254}. Best is trial 0 with value: 0.5876234289654728.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:27:23,819]\u001b[0m Trial 1 finished with value: 0.5915567496377735 and parameters: {'n_estimators': 478, 'max_depth': 10, 'learning_rate': 0.012257787043447078, 'subsample': 0.8244417984225176, 'colsample_bytree': 0.5202736229026061}. Best is trial 1 with value: 0.5915567496377735.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:28:18,342]\u001b[0m Trial 2 finished with value: 0.5867537850074582 and parameters: {'n_estimators': 679, 'max_depth': 74, 'learning_rate': 0.07327905465508809, 'subsample': 0.35224951836164237, 'colsample_bytree': 0.8619017734713907}. Best is trial 1 with value: 0.5915567496377735.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:28:50,181]\u001b[0m Trial 3 finished with value: 0.5521761347722 and parameters: {'n_estimators': 711, 'max_depth': 47, 'learning_rate': 0.28355767533929943, 'subsample': 0.5821064725110621, 'colsample_bytree': 0.38235791061278307}. Best is trial 1 with value: 0.5915567496377735.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:29:12,389]\u001b[0m Trial 4 finished with value: 0.5705718461453477 and parameters: {'n_estimators': 295, 'max_depth': 44, 'learning_rate': 0.26901883346546823, 'subsample': 0.5782438453096697, 'colsample_bytree': 0.7651543764103912}. Best is trial 1 with value: 0.5915567496377735.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:30:05,696]\u001b[0m Trial 5 finished with value: 0.55318503196552 and parameters: {'n_estimators': 830, 'max_depth': 17, 'learning_rate': 0.22767413597119052, 'subsample': 0.5782063298034568, 'colsample_bytree': 0.709599919674403}. Best is trial 1 with value: 0.5915567496377735.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:30:38,716]\u001b[0m Trial 6 finished with value: 0.5643902016934821 and parameters: {'n_estimators': 773, 'max_depth': 27, 'learning_rate': 0.2058288663332732, 'subsample': 0.45738411298314574, 'colsample_bytree': 0.34500635165260685}. Best is trial 1 with value: 0.5915567496377735.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:31:05,622]\u001b[0m Trial 7 finished with value: 0.58806895591317 and parameters: {'n_estimators': 447, 'max_depth': 11, 'learning_rate': 0.0938930385590698, 'subsample': 0.802193093324514, 'colsample_bytree': 0.5203949822343783}. Best is trial 1 with value: 0.5915567496377735.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:31:28,783]\u001b[0m Trial 8 finished with value: 0.5907462351484581 and parameters: {'n_estimators': 429, 'max_depth': 55, 'learning_rate': 0.07795328535681358, 'subsample': 0.9457692627619954, 'colsample_bytree': 0.3931982000249525}. Best is trial 1 with value: 0.5915567496377735.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:32:02,041]\u001b[0m Trial 9 finished with value: 0.5637370970792294 and parameters: {'n_estimators': 605, 'max_depth': 29, 'learning_rate': 0.22591046331445344, 'subsample': 0.6553573535770674, 'colsample_bytree': 0.5362917520016759}. Best is trial 1 with value: 0.5915567496377735.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:32:11,528]\u001b[0m Trial 10 finished with value: 0.5717884143575619 and parameters: {'n_estimators': 127, 'max_depth': 97, 'learning_rate': 0.010733702050751831, 'subsample': 0.9670439442428314, 'colsample_bytree': 0.2061634790318584}. Best is trial 1 with value: 0.5915567496377735.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:33:15,685]\u001b[0m Trial 11 finished with value: 0.5928004895873265 and parameters: {'n_estimators': 976, 'max_depth': 60, 'learning_rate': 0.010719351212571827, 'subsample': 0.9742260389310529, 'colsample_bytree': 0.36610044467968594}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:34:03,730]\u001b[0m Trial 12 finished with value: 0.5927389032758051 and parameters: {'n_estimators': 885, 'max_depth': 70, 'learning_rate': 0.01035263865536131, 'subsample': 0.7991997043495294, 'colsample_bytree': 0.21218813155121394}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:34:40,526]\u001b[0m Trial 13 finished with value: 0.5761802042622295 and parameters: {'n_estimators': 996, 'max_depth': 71, 'learning_rate': 0.13602819484153997, 'subsample': 0.8080642553596762, 'colsample_bytree': 0.2315788899112815}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:35:25,131]\u001b[0m Trial 14 finished with value: 0.5902586888437942 and parameters: {'n_estimators': 964, 'max_depth': 74, 'learning_rate': 0.04592720078644533, 'subsample': 0.8871477812698634, 'colsample_bytree': 0.3268833611058444}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:36:00,067]\u001b[0m Trial 15 finished with value: 0.5718585956830473 and parameters: {'n_estimators': 863, 'max_depth': 93, 'learning_rate': 0.14987005231956055, 'subsample': 0.7341262119225458, 'colsample_bytree': 0.2939219098260635}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:36:44,110]\u001b[0m Trial 16 finished with value: 0.5781098360319114 and parameters: {'n_estimators': 887, 'max_depth': 62, 'learning_rate': 0.11204030870946924, 'subsample': 0.20274327366058542, 'colsample_bytree': 0.44483545551587095}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:37:43,167]\u001b[0m Trial 17 finished with value: 0.5908561677274525 and parameters: {'n_estimators': 623, 'max_depth': 85, 'learning_rate': 0.04742213269405245, 'subsample': 0.9882731835307556, 'colsample_bytree': 0.9976246612433533}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:38:23,464]\u001b[0m Trial 18 finished with value: 0.5918820372717484 and parameters: {'n_estimators': 932, 'max_depth': 35, 'learning_rate': 0.0450572913409904, 'subsample': 0.708417784659064, 'colsample_bytree': 0.263749378843224}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:39:10,237]\u001b[0m Trial 19 finished with value: 0.566577414238193 and parameters: {'n_estimators': 766, 'max_depth': 61, 'learning_rate': 0.175349505142056, 'subsample': 0.9061994754513617, 'colsample_bytree': 0.6370132325522222}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:39:39,399]\u001b[0m Trial 20 finished with value: 0.5822469107920855 and parameters: {'n_estimators': 573, 'max_depth': 84, 'learning_rate': 0.1230895409763732, 'subsample': 0.8716064089472664, 'colsample_bytree': 0.41682252666248215}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:40:21,947]\u001b[0m Trial 21 finished with value: 0.5909411987495098 and parameters: {'n_estimators': 954, 'max_depth': 37, 'learning_rate': 0.043486570415624426, 'subsample': 0.7083785015036997, 'colsample_bytree': 0.2828147367885459}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:41:00,768]\u001b[0m Trial 22 finished with value: 0.5921480746235362 and parameters: {'n_estimators': 888, 'max_depth': 56, 'learning_rate': 0.025478973476334855, 'subsample': 0.7722659892717298, 'colsample_bytree': 0.20500857109721932}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:41:44,006]\u001b[0m Trial 23 finished with value: 0.5922651224560873 and parameters: {'n_estimators': 816, 'max_depth': 66, 'learning_rate': 0.012562648546456548, 'subsample': 0.7556898471247475, 'colsample_bytree': 0.21175589371357556}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:42:16,458]\u001b[0m Trial 24 finished with value: 0.5850878534869114 and parameters: {'n_estimators': 751, 'max_depth': 67, 'learning_rate': 0.08281545750590724, 'subsample': 0.6558246336407324, 'colsample_bytree': 0.312384405222218}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:42:51,172]\u001b[0m Trial 25 finished with value: 0.5885642416919914 and parameters: {'n_estimators': 829, 'max_depth': 87, 'learning_rate': 0.06323499328764591, 'subsample': 0.8829267193344935, 'colsample_bytree': 0.2625157313006311}. Best is trial 11 with value: 0.5928004895873265.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:43:48,064]\u001b[0m Trial 26 finished with value: 0.593063047060746 and parameters: {'n_estimators': 1000, 'max_depth': 80, 'learning_rate': 0.03326308555503022, 'subsample': 0.4951910141758966, 'colsample_bytree': 0.4531991441537735}. Best is trial 26 with value: 0.593063047060746.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:44:50,675]\u001b[0m Trial 28 finished with value: 0.5896075382800479 and parameters: {'n_estimators': 30, 'max_depth': 55, 'learning_rate': 0.10353799107103318, 'subsample': 0.49375324604065485, 'colsample_bytree': 0.5945911603192052}. Best is trial 26 with value: 0.593063047060746.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:45:13,006]\u001b[0m Trial 29 finished with value: 0.5942254135322618 and parameters: {'n_estimators': 328, 'max_depth': 92, 'learning_rate': 0.060924886270700813, 'subsample': 0.40308059289409526, 'colsample_bytree': 0.4849259123203934}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:45:34,496]\u001b[0m Trial 30 finished with value: 0.5917551469779093 and parameters: {'n_estimators': 318, 'max_depth': 99, 'learning_rate': 0.06598501153349161, 'subsample': 0.3399939829960546, 'colsample_bytree': 0.4820056559911001}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:46:02,531]\u001b[0m Trial 31 finished with value: 0.593233659592239 and parameters: {'n_estimators': 314, 'max_depth': 91, 'learning_rate': 0.030440153102755003, 'subsample': 0.3976374021773592, 'colsample_bytree': 0.5878087645305305}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:46:27,871]\u001b[0m Trial 32 finished with value: 0.5929004240802858 and parameters: {'n_estimators': 269, 'max_depth': 91, 'learning_rate': 0.03003622403056757, 'subsample': 0.3847854156615356, 'colsample_bytree': 0.6000511447747026}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:46:48,818]\u001b[0m Trial 33 finished with value: 0.5913968621901413 and parameters: {'n_estimators': 253, 'max_depth': 91, 'learning_rate': 0.05695838046830218, 'subsample': 0.37871949216286277, 'colsample_bytree': 0.5873948093113214}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:47:21,897]\u001b[0m Trial 34 finished with value: 0.5927398522217595 and parameters: {'n_estimators': 381, 'max_depth': 79, 'learning_rate': 0.03289980115937357, 'subsample': 0.27765262360248244, 'colsample_bytree': 0.6648197368623125}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:47:38,486]\u001b[0m Trial 35 finished with value: 0.5899883894077849 and parameters: {'n_estimators': 221, 'max_depth': 92, 'learning_rate': 0.09151508832990594, 'subsample': 0.4004630545578925, 'colsample_bytree': 0.5452085791417232}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:48:24,086]\u001b[0m Trial 36 finished with value: 0.591670630548163 and parameters: {'n_estimators': 522, 'max_depth': 80, 'learning_rate': 0.03181172451428021, 'subsample': 0.5219999539624729, 'colsample_bytree': 0.7381476978796726}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:48:43,033]\u001b[0m Trial 37 finished with value: 0.5905271297871073 and parameters: {'n_estimators': 174, 'max_depth': 100, 'learning_rate': 0.0708404267271252, 'subsample': 0.4230358087308767, 'colsample_bytree': 0.8348961120681772}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:49:05,668]\u001b[0m Trial 38 finished with value: 0.5790509508857875 and parameters: {'n_estimators': 342, 'max_depth': 90, 'learning_rate': 0.17273882168864108, 'subsample': 0.31458624652435724, 'colsample_bytree': 0.6319228018462651}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:49:30,367]\u001b[0m Trial 39 finished with value: 0.5921244642492293 and parameters: {'n_estimators': 373, 'max_depth': 83, 'learning_rate': 0.056563496529167055, 'subsample': 0.5477983919826711, 'colsample_bytree': 0.48791842951051073}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:49:49,449]\u001b[0m Trial 40 finished with value: 0.5903476466225157 and parameters: {'n_estimators': 265, 'max_depth': 76, 'learning_rate': 0.08232837822223227, 'subsample': 0.2756637758595396, 'colsample_bytree': 0.5622146830783162}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:50:02,916]\u001b[0m Trial 41 finished with value: 0.589559867455519 and parameters: {'n_estimators': 150, 'max_depth': 95, 'learning_rate': 0.022511783841230724, 'subsample': 0.43610006926513534, 'colsample_bytree': 0.3632695882149979}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:50:12,432]\u001b[0m Trial 42 finished with value: 0.5884096715880787 and parameters: {'n_estimators': 80, 'max_depth': 88, 'learning_rate': 0.03681983028003087, 'subsample': 0.49020901315666593, 'colsample_bytree': 0.49772963051082314}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:50:47,048]\u001b[0m Trial 43 finished with value: 0.5930833589331085 and parameters: {'n_estimators': 493, 'max_depth': 48, 'learning_rate': 0.020605094399270028, 'subsample': 0.3689888588112725, 'colsample_bytree': 0.4013747913087055}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:51:15,732]\u001b[0m Trial 44 finished with value: 0.5923969736813609 and parameters: {'n_estimators': 494, 'max_depth': 51, 'learning_rate': 0.05641808272116438, 'subsample': 0.39774487275315296, 'colsample_bytree': 0.43188272367114716}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:51:43,415]\u001b[0m Trial 45 finished with value: 0.5620557985989403 and parameters: {'n_estimators': 415, 'max_depth': 46, 'learning_rate': 0.263678523916689, 'subsample': 0.35559894621170324, 'colsample_bytree': 0.6878091488269942}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:52:23,737]\u001b[0m Trial 46 finished with value: 0.5934793822143111 and parameters: {'n_estimators': 671, 'max_depth': 39, 'learning_rate': 0.02514792311568657, 'subsample': 0.29850104191244586, 'colsample_bytree': 0.3941147605608068}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:53:07,510]\u001b[0m Trial 47 finished with value: 0.5941116315722105 and parameters: {'n_estimators': 671, 'max_depth': 41, 'learning_rate': 0.020331304639864656, 'subsample': 0.26951285413679327, 'colsample_bytree': 0.39763699249878554}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:53:52,047]\u001b[0m Trial 48 finished with value: 0.5928738225670342 and parameters: {'n_estimators': 684, 'max_depth': 41, 'learning_rate': 0.020122587705165455, 'subsample': 0.20095014678059575, 'colsample_bytree': 0.3968931076167132}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:54:22,054]\u001b[0m Trial 49 finished with value: 0.593231451573082 and parameters: {'n_estimators': 551, 'max_depth': 25, 'learning_rate': 0.04342360694243402, 'subsample': 0.2574939780705169, 'colsample_bytree': 0.3483319673026301}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:54:52,950]\u001b[0m Trial 50 finished with value: 0.5887937880402698 and parameters: {'n_estimators': 642, 'max_depth': 20, 'learning_rate': 0.07436932308222494, 'subsample': 0.27567647794425226, 'colsample_bytree': 0.3535476236046459}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:55:07,325]\u001b[0m Trial 51 finished with value: 0.5843712075550559 and parameters: {'n_estimators': 547, 'max_depth': 1, 'learning_rate': 0.04570397559688744, 'subsample': 0.2443476694319892, 'colsample_bytree': 0.39413977436184894}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:55:42,471]\u001b[0m Trial 52 finished with value: 0.5931114882222999 and parameters: {'n_estimators': 476, 'max_depth': 34, 'learning_rate': 0.01856245135701797, 'subsample': 0.31547338783381706, 'colsample_bytree': 0.4101867381004802}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:56:07,799]\u001b[0m Trial 53 finished with value: 0.5932059109128542 and parameters: {'n_estimators': 463, 'max_depth': 26, 'learning_rate': 0.053657362575575754, 'subsample': 0.3125125618561161, 'colsample_bytree': 0.3336711847231244}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:56:51,665]\u001b[0m Trial 54 finished with value: 0.5898409043475397 and parameters: {'n_estimators': 725, 'max_depth': 25, 'learning_rate': 0.052659933322573724, 'subsample': 0.2368309324139573, 'colsample_bytree': 0.5178005487012455}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:57:18,517]\u001b[0m Trial 55 finished with value: 0.5865657648337519 and parameters: {'n_estimators': 588, 'max_depth': 31, 'learning_rate': 0.09662218317249457, 'subsample': 0.31886821883438216, 'colsample_bytree': 0.328438581627275}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:57:52,341]\u001b[0m Trial 56 finished with value: 0.5931668779163006 and parameters: {'n_estimators': 655, 'max_depth': 24, 'learning_rate': 0.04303190361616601, 'subsample': 0.2441873453518586, 'colsample_bytree': 0.3343470194087245}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:58:16,819]\u001b[0m Trial 57 finished with value: 0.5899322094322252 and parameters: {'n_estimators': 449, 'max_depth': 13, 'learning_rate': 0.06325656609902916, 'subsample': 0.2931269654194572, 'colsample_bytree': 0.37396917852432265}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:58:37,809]\u001b[0m Trial 58 finished with value: 0.5601948802904996 and parameters: {'n_estimators': 552, 'max_depth': 40, 'learning_rate': 0.2940005115874303, 'subsample': 0.2306825441031385, 'colsample_bytree': 0.2444022854964849}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:59:07,986]\u001b[0m Trial 59 finished with value: 0.5868405422897703 and parameters: {'n_estimators': 681, 'max_depth': 21, 'learning_rate': 0.08624375561504638, 'subsample': 0.3267570437969394, 'colsample_bytree': 0.3005603911963677}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 07:59:30,076]\u001b[0m Trial 60 finished with value: 0.5864141871007561 and parameters: {'n_estimators': 399, 'max_depth': 30, 'learning_rate': 0.11879713665041822, 'subsample': 0.35194160210369874, 'colsample_bytree': 0.43618602845850574}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:00:03,370]\u001b[0m Trial 61 finished with value: 0.5920250422701854 and parameters: {'n_estimators': 638, 'max_depth': 24, 'learning_rate': 0.041189556966552805, 'subsample': 0.2575083918195083, 'colsample_bytree': 0.3294643567419969}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:00:39,920]\u001b[0m Trial 62 finished with value: 0.5928171726151314 and parameters: {'n_estimators': 657, 'max_depth': 15, 'learning_rate': 0.0382582621467275, 'subsample': 0.2988459992287341, 'colsample_bytree': 0.3556399646213657}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:01:32,725]\u001b[0m Trial 63 finished with value: 0.5921672308688419 and parameters: {'n_estimators': 600, 'max_depth': 42, 'learning_rate': 0.010047125944191694, 'subsample': 0.22824337180902202, 'colsample_bytree': 0.46896471724589617}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:01:59,327]\u001b[0m Trial 64 finished with value: 0.5923169832651993 and parameters: {'n_estimators': 451, 'max_depth': 8, 'learning_rate': 0.049984745845033304, 'subsample': 0.26393596492280363, 'colsample_bytree': 0.33844417782620584}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:02:33,208]\u001b[0m Trial 65 finished with value: 0.5884690898695639 and parameters: {'n_estimators': 800, 'max_depth': 36, 'learning_rate': 0.07054671300252405, 'subsample': 0.4270734197085793, 'colsample_bytree': 0.2664429573402636}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:03:20,078]\u001b[0m Trial 66 finished with value: 0.593280770143554 and parameters: {'n_estimators': 745, 'max_depth': 28, 'learning_rate': 0.024389283251165815, 'subsample': 0.22317301612017099, 'colsample_bytree': 0.4255998328922127}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:04:10,083]\u001b[0m Trial 67 finished with value: 0.5920577903218808 and parameters: {'n_estimators': 716, 'max_depth': 38, 'learning_rate': 0.024738236031764275, 'subsample': 0.21363018983679466, 'colsample_bytree': 0.5103991727321204}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:05:02,751]\u001b[0m Trial 68 finished with value: 0.5930995807583632 and parameters: {'n_estimators': 754, 'max_depth': 32, 'learning_rate': 0.01725214756281062, 'subsample': 0.29321376923934556, 'colsample_bytree': 0.4269800997867352}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:05:40,332]\u001b[0m Trial 69 finished with value: 0.5926807961279473 and parameters: {'n_estimators': 346, 'max_depth': 27, 'learning_rate': 0.061376921620232616, 'subsample': 0.3464243243222123, 'colsample_bytree': 0.9965128710140079}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:06:07,072]\u001b[0m Trial 70 finished with value: 0.5701517150793369 and parameters: {'n_estimators': 553, 'max_depth': 19, 'learning_rate': 0.2011446134145534, 'subsample': 0.608492508270066, 'colsample_bytree': 0.3821676024263235}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:06:42,603]\u001b[0m Trial 71 finished with value: 0.5924987607872089 and parameters: {'n_estimators': 699, 'max_depth': 24, 'learning_rate': 0.04009373560563563, 'subsample': 0.2597256840393469, 'colsample_bytree': 0.2999437638218577}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:07:21,002]\u001b[0m Trial 72 finished with value: 0.5918942368240127 and parameters: {'n_estimators': 616, 'max_depth': 28, 'learning_rate': 0.048743586141891344, 'subsample': 0.296716436549684, 'colsample_bytree': 0.4725293625061917}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:08:18,224]\u001b[0m Trial 73 finished with value: 0.5912800493122398 and parameters: {'n_estimators': 793, 'max_depth': 33, 'learning_rate': 0.026047560058110462, 'subsample': 0.21502903200573092, 'colsample_bytree': 0.547763428008311}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:08:54,899]\u001b[0m Trial 74 finished with value: 0.593900158848641 and parameters: {'n_estimators': 736, 'max_depth': 22, 'learning_rate': 0.03592093141365646, 'subsample': 0.25204681615670504, 'colsample_bytree': 0.2773530031136532}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:09:32,095]\u001b[0m Trial 75 finished with value: 0.5926063161661899 and parameters: {'n_estimators': 738, 'max_depth': 18, 'learning_rate': 0.031994595787531145, 'subsample': 0.33515404832801937, 'colsample_bytree': 0.27956180785569984}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:09:53,419]\u001b[0m Trial 76 finished with value: 0.587839052065599 and parameters: {'n_estimators': 312, 'max_depth': 8, 'learning_rate': 0.01081049512810638, 'subsample': 0.40397846313494234, 'colsample_bytree': 0.24804883833981412}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:10:35,665]\u001b[0m Trial 77 finished with value: 0.5925866351183442 and parameters: {'n_estimators': 840, 'max_depth': 51, 'learning_rate': 0.03503735198164218, 'subsample': 0.3726058472855668, 'colsample_bytree': 0.3152427034864274}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:11:07,124]\u001b[0m Trial 78 finished with value: 0.5906147723569172 and parameters: {'n_estimators': 522, 'max_depth': 44, 'learning_rate': 0.05399127371569805, 'subsample': 0.30517858957152416, 'colsample_bytree': 0.444310175998529}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:11:25,178]\u001b[0m Trial 79 finished with value: 0.5908899825757352 and parameters: {'n_estimators': 204, 'max_depth': 22, 'learning_rate': 0.026906069763219825, 'subsample': 0.27881314956821945, 'colsample_bytree': 0.41497395898795875}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:12:04,335]\u001b[0m Trial 80 finished with value: 0.5847145514229731 and parameters: {'n_estimators': 780, 'max_depth': 39, 'learning_rate': 0.07837426999843772, 'subsample': 0.4473144777471909, 'colsample_bytree': 0.37892168616495436}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:12:39,776]\u001b[0m Trial 81 finished with value: 0.5939882587966051 and parameters: {'n_estimators': 663, 'max_depth': 25, 'learning_rate': 0.04176554916143358, 'subsample': 0.2506125795444461, 'colsample_bytree': 0.3483894068749812}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:13:11,439]\u001b[0m Trial 82 finished with value: 0.5796627580052347 and parameters: {'n_estimators': 700, 'max_depth': 28, 'learning_rate': 0.14029663632225486, 'subsample': 0.25189136194643746, 'colsample_bytree': 0.35149958864007136}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:14:17,020]\u001b[0m Trial 84 finished with value: 0.5924850377111166 and parameters: {'n_estimators': 283, 'max_depth': 30, 'learning_rate': 0.0654988070529741, 'subsample': 0.26778376714646074, 'colsample_bytree': 0.28390944887299874}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:14:43,625]\u001b[0m Trial 85 finished with value: 0.5928651082760787 and parameters: {'n_estimators': 575, 'max_depth': 35, 'learning_rate': 0.04178727615758733, 'subsample': 0.20358749154452868, 'colsample_bytree': 0.22860984888025837}. Best is trial 29 with value: 0.5942254135322618.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:15:18,053]\u001b[0m Trial 86 finished with value: 0.5949964005116721 and parameters: {'n_estimators': 623, 'max_depth': 95, 'learning_rate': 0.02784962418597878, 'subsample': 0.4699768259199653, 'colsample_bytree': 0.31085887604836576}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:15:52,051]\u001b[0m Trial 87 finished with value: 0.5936315639002665 and parameters: {'n_estimators': 611, 'max_depth': 88, 'learning_rate': 0.029597271027560247, 'subsample': 0.5317509642451459, 'colsample_bytree': 0.30849054386061275}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:16:32,086]\u001b[0m Trial 88 finished with value: 0.5937825857396347 and parameters: {'n_estimators': 620, 'max_depth': 97, 'learning_rate': 0.01625848149952357, 'subsample': 0.5377113567880034, 'colsample_bytree': 0.31494176132805973}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:17:11,927]\u001b[0m Trial 89 finished with value: 0.5932843951308933 and parameters: {'n_estimators': 643, 'max_depth': 95, 'learning_rate': 0.017175430160086082, 'subsample': 0.551114324901344, 'colsample_bytree': 0.3076665047241034}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:17:52,384]\u001b[0m Trial 90 finished with value: 0.5924954162943397 and parameters: {'n_estimators': 629, 'max_depth': 96, 'learning_rate': 0.01481219967492521, 'subsample': 0.5470494295502814, 'colsample_bytree': 0.30978417765743993}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:18:26,574]\u001b[0m Trial 91 finished with value: 0.594769978743004 and parameters: {'n_estimators': 615, 'max_depth': 94, 'learning_rate': 0.024969215384455345, 'subsample': 0.6147438288638506, 'colsample_bytree': 0.2827883379668692}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:18:56,650]\u001b[0m Trial 92 finished with value: 0.5934350633667543 and parameters: {'n_estimators': 603, 'max_depth': 98, 'learning_rate': 0.03417968163392203, 'subsample': 0.6299439779306933, 'colsample_bytree': 0.26695111062976834}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:19:25,066]\u001b[0m Trial 93 finished with value: 0.5941379425075426 and parameters: {'n_estimators': 601, 'max_depth': 100, 'learning_rate': 0.03212943136260736, 'subsample': 0.6103668910523758, 'colsample_bytree': 0.22778323763022523}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:19:58,445]\u001b[0m Trial 94 finished with value: 0.593054592041392 and parameters: {'n_estimators': 691, 'max_depth': 88, 'learning_rate': 0.02853583832397147, 'subsample': 0.6576077798799747, 'colsample_bytree': 0.2429657692518194}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:20:24,521]\u001b[0m Trial 95 finished with value: 0.5928912912006044 and parameters: {'n_estimators': 575, 'max_depth': 93, 'learning_rate': 0.03689686171922382, 'subsample': 0.5721356078852137, 'colsample_bytree': 0.20183858095455426}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:20:57,726]\u001b[0m Trial 96 finished with value: 0.5938911701139442 and parameters: {'n_estimators': 668, 'max_depth': 99, 'learning_rate': 0.022589606466343653, 'subsample': 0.5219663695523449, 'colsample_bytree': 0.22252487654738998}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:21:27,845]\u001b[0m Trial 97 finished with value: 0.5920937141216603 and parameters: {'n_estimators': 622, 'max_depth': 100, 'learning_rate': 0.04800963991277334, 'subsample': 0.4736307677879047, 'colsample_bytree': 0.28003767928509193}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:22:00,360]\u001b[0m Trial 98 finished with value: 0.5924823391151699 and parameters: {'n_estimators': 596, 'max_depth': 94, 'learning_rate': 0.016743665208628893, 'subsample': 0.5205027513786478, 'colsample_bytree': 0.22284273376442695}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n",
            "\u001b[32m[I 2021-12-10 08:22:30,551]\u001b[0m Trial 99 finished with value: 0.5901206899582776 and parameters: {'n_estimators': 724, 'max_depth': 86, 'learning_rate': 0.059760996707882943, 'subsample': 0.6031577271631352, 'colsample_bytree': 0.21959233327522448}. Best is trial 86 with value: 0.5949964005116721.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best F1 score: 0.5949964005116721\n",
            "Best hyperparameters: {'n_estimators': 623, 'max_depth': 95, 'learning_rate': 0.02784962418597878, 'subsample': 0.4699768259199653, 'colsample_bytree': 0.31085887604836576}\n"
          ]
        }
      ],
      "source": [
        "def objective_SoftVoting(trial):\n",
        "      n_estimators_values = trial.suggest_int('n_estimators', 10, 1000)\n",
        "      max_depth_values = trial.suggest_int('max_depth', 1, 100)\n",
        "      learning_rate_values = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
        "      subsample_values = trial.suggest_float('subsample', 0.2, 1)\n",
        "      colsample_bytree_values = trial.suggest_float('colsample_bytree', 0.2, 1)\n",
        "      clf1 = LGBMClassifier(scale_pos_weight=scale_pos_weight_data, \n",
        "                          n_estimators=n_estimators_values,\n",
        "                          max_depth=max_depth_values,\n",
        "                          learning_rate=learning_rate_values,\n",
        "                          subsample=subsample_values,\n",
        "                          colsample_bytree=colsample_bytree_values)\n",
        "      clf2 = XGBClassifier(scale_pos_weight=scale_pos_weight_data)\n",
        "      estimators=[]\n",
        "      estimators.append(('lgbm', clf1))\n",
        "      estimators.append(('xgb', clf2))\n",
        "      clf = VotingClassifier(estimators, voting='hard')\n",
        "      model_f1scores = cross_val_score(estimator = clf, X = X_train, y = Y_train, cv = k_fold, scoring = 'f1')\n",
        "      return model_f1scores.mean()\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective_LightGBM, n_trials=100)\n",
        "\n",
        "trial = study.best_trial\n",
        "print('Best F1 score: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRqf8tBQIchw"
      },
      "source": [
        "## (E) Reporting the final train and test scores for all 4 models(with tuned hyperparamaters)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into train and test sets \n",
        "\n",
        "X_train = X_train_unscaled\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2,shuffle=True,stratify=Y_train) \n",
        "# stratify=Y_train is used since its an imbalanced dataset. This parameter ensures that the data gets split according to the proportion of Y_train\n",
        "\n",
        "\n",
        "# Scaling all columns\n",
        "scaler = MinMaxScaler();\n",
        "scaler.fit(x_train);\n",
        "x_train = scaler.transform(x_train);\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "# =================  Model 1: LGBM with tuned hyperparameters: ===================================\n",
        "\n",
        "# Best hyperparameters found out using hyperparameter tuning\n",
        "best_hyperparameters = {'n_estimators': 760, 'max_depth': 85, 'learning_rate': 0.02935086260767057, 'subsample': 0.3792225838646886, 'colsample_bytree': 0.21433910546560286}\n",
        "model = LGBMClassifier(**best_hyperparameters, scale_pos_weight=scale_pos_weight_data)\n",
        "model.fit(x_train, y_train)\n",
        "train_preds = model.predict(x_train)\n",
        "test_preds = model.predict(x_test)\n",
        "\n",
        "# Printing out accuracy, F1 score and balanced accuracy for train and test datasets\n",
        "print(\"\\nLGBM: \")\n",
        "print(\"Train Accuracy:\", accuracy_score(train_preds, y_train));\n",
        "print(\"Test Accuracy:\", accuracy_score(test_preds, y_test));\n",
        "train_f1 = f1_score(train_preds, y_train);\n",
        "test_f1 = f1_score(test_preds, y_test);\n",
        "print(\"Train F1: {}\".format(train_f1));\n",
        "print(\"Test F1: {}\".format(test_f1));\n",
        "train_bac = balanced_accuracy_score(y_train, train_preds)\n",
        "test_bac = balanced_accuracy_score(y_test, test_preds)\n",
        "print(\"Train Balanced Accuracy: {}\".format(train_bac))\n",
        "print(\"Test Balanced Accuracy: {}\".format(test_bac))\n",
        "\n",
        "# =================  Model 2: XGBoost (tuning was not done): ===================================\n",
        "\n",
        "# Best hyperparameters found out using hyperparameter tuning\n",
        "model = XGBClassifier(scale_pos_weight=scale_pos_weight_data)\n",
        "model.fit(x_train, y_train)\n",
        "train_preds = model.predict(x_train)\n",
        "test_preds = model.predict(x_test)\n",
        "\n",
        "# Printing out accuracy, F1 score and balanced accuracy for train and test datasets\n",
        "print(\"\\nXGBoost: \")\n",
        "print(\"Train Accuracy:\", accuracy_score(train_preds, y_train));\n",
        "print(\"Test Accuracy:\", accuracy_score(test_preds, y_test));\n",
        "train_f1 = f1_score(train_preds, y_train);\n",
        "test_f1 = f1_score(test_preds, y_test);\n",
        "print(\"Train F1: {}\".format(train_f1));\n",
        "print(\"Test F1: {}\".format(test_f1));\n",
        "train_bac = balanced_accuracy_score(y_train, train_preds)\n",
        "test_bac = balanced_accuracy_score(y_test, test_preds)\n",
        "print(\"Train Balanced Accuracy: {}\".format(train_bac))\n",
        "print(\"Test Balanced Accuracy: {}\".format(test_bac))\n",
        "\n",
        "\n",
        "# =================  Model 3: LGBM + XGBoost Soft Voting (tuning was done for hyperparameters of LGBM only): ===================================\n",
        "\n",
        "estimators = []\n",
        "\n",
        "# Best hyperparameters of LGBM in soft voting found out using hyperparameter tuning\n",
        "best_hyperparameters = {'n_estimators': 300, 'max_depth': 79, 'learning_rate': 0.04208439247743048, 'subsample': 0.4377450353973782, 'colsample_bytree': 0.2970209187817083}\n",
        "model_1 = LGBMClassifier(**best_hyperparameters,scale_pos_weight=scale_pos_weight_data)\n",
        "estimators.append(('lgbm', model_1))\n",
        "\n",
        "model_2 = XGBClassifier(scale_pos_weight=scale_pos_weight_data)\n",
        "estimators.append(('xgb', model_2))\n",
        "\n",
        "model = VotingClassifier(estimators, voting='soft')\n",
        "model.fit(x_train, y_train)\n",
        "train_preds = model.predict(x_train)\n",
        "test_preds = model.predict(x_test)\n",
        "\n",
        "# Printing out accuracy, F1 score and balanced accuracy for train and test datasets\n",
        "print(\"\\nLGBM + XGBoost Soft Voting: \")\n",
        "print(\"Train Accuracy:\", accuracy_score(train_preds, y_train));\n",
        "print(\"Test Accuracy:\", accuracy_score(test_preds, y_test));\n",
        "train_f1 = f1_score(train_preds, y_train);\n",
        "test_f1 = f1_score(test_preds, y_test);\n",
        "print(\"Train F1: {}\".format(train_f1));\n",
        "print(\"Test F1: {}\".format(test_f1));\n",
        "train_bac = balanced_accuracy_score(y_train, train_preds)\n",
        "test_bac = balanced_accuracy_score(y_test, test_preds)\n",
        "print(\"Train Balanced Accuracy: {}\".format(train_bac))\n",
        "print(\"Test Balanced Accuracy: {}\".format(test_bac))\n",
        "\n",
        "\n",
        "# =================  Model 4: LGBM + XGBoost Hard Voting (tuning was done for hyperparameters of LGBM only): ===================================\n",
        "\n",
        "estimators = []\n",
        "\n",
        "# Best hyperparameters of LGBM in Hard voting found out using hyperparameter tuning\n",
        "best_hyperparameters = {'n_estimators': 623, 'max_depth': 95, 'learning_rate': 0.02784962418597878, 'subsample': 0.4699768259199653, 'colsample_bytree': 0.31085887604836576}\n",
        "model_1 = LGBMClassifier(**best_hyperparameters,scale_pos_weight=scale_pos_weight_data)\n",
        "estimators.append(('lgbm', model_1))\n",
        "\n",
        "model_2 = XGBClassifier(scale_pos_weight=scale_pos_weight_data)\n",
        "estimators.append(('xgb', model_2))\n",
        "\n",
        "model = VotingClassifier(estimators, voting='hard')\n",
        "model.fit(x_train, y_train)\n",
        "train_preds = model.predict(x_train)\n",
        "test_preds = model.predict(x_test)\n",
        "\n",
        "# Printing out accuracy, F1 score and balanced accuracy for train and test datasets\n",
        "print(\"\\nLGBM + XGBoost Hard Voting: \")\n",
        "print(\"Train Accuracy:\", accuracy_score(train_preds, y_train));\n",
        "print(\"Test Accuracy:\", accuracy_score(test_preds, y_test));\n",
        "train_f1 = f1_score(train_preds, y_train);\n",
        "test_f1 = f1_score(test_preds, y_test);\n",
        "print(\"Train F1: {}\".format(train_f1));\n",
        "print(\"Test F1: {}\".format(test_f1));\n",
        "train_bac = balanced_accuracy_score(y_train, train_preds)\n",
        "test_bac = balanced_accuracy_score(y_test, test_preds)\n",
        "print(\"Train Balanced Accuracy: {}\".format(train_bac))\n",
        "print(\"Test Balanced Accuracy: {}\".format(test_bac))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZxzDaHGcqxJ",
        "outputId": "1b1a4072-81a2-49fe-bc44-ad38cf820c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LGBM: \n",
            "Train Accuracy: 0.7735090361445783\n",
            "Test Accuracy: 0.7292771084337349\n",
            "Train F1: 0.6581967771994818\n",
            "Test F1: 0.590486604702023\n",
            "Train Balanced Accuracy: 0.7691061394699097\n",
            "Test Balanced Accuracy: 0.7143084099681554\n",
            "\n",
            "XGBoost: \n",
            "Train Accuracy: 0.7239006024096386\n",
            "Test Accuracy: 0.7171686746987952\n",
            "Train F1: 0.5981455908463208\n",
            "Test F1: 0.5898488686992224\n",
            "Train Balanced Accuracy: 0.7212286740669223\n",
            "Test Balanced Accuracy: 0.7143165341922011\n",
            "\n",
            "LGBM + XGBoost Soft Voting: \n",
            "Train Accuracy: 0.7410993975903615\n",
            "Test Accuracy: 0.7232530120481928\n",
            "Train F1: 0.6179523079316399\n",
            "Test F1: 0.5924414478353441\n",
            "Train Balanced Accuracy: 0.7373453449409979\n",
            "Test Balanced Accuracy: 0.716272062384685\n",
            "\n",
            "LGBM + XGBoost Hard Voting: \n",
            "Train Accuracy: 0.7594728915662651\n",
            "Test Accuracy: 0.7337951807228915\n",
            "Train F1: 0.62723771735325\n",
            "Test F1: 0.5905679607152785\n",
            "Train Balanced Accuracy: 0.7429525479400538\n",
            "Test Balanced Accuracy: 0.7141644508443603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI5oMHGwzVg9"
      },
      "source": [
        "## (F) Predictions on the test dataset and final csv submission: Need to be completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sago4X50zVg-"
      },
      "outputs": [],
      "source": [
        "## Training of the final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qGmuIBnJzVhA",
        "outputId": "469f1b31-5e8c-4746-b854-2bdd87beb83f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>578069</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>578070</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>578071</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>578072</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>578073</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46995</th>\n",
              "      <td>310027</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46996</th>\n",
              "      <td>310028</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46997</th>\n",
              "      <td>310029</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46998</th>\n",
              "      <td>310030</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46999</th>\n",
              "      <td>310031</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47000 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          key  prediction\n",
              "0      578069           0\n",
              "1      578070           0\n",
              "2      578071           0\n",
              "3      578072           0\n",
              "4      578073           0\n",
              "...       ...         ...\n",
              "46995  310027           0\n",
              "46996  310028           0\n",
              "46997  310029           1\n",
              "46998  310030           0\n",
              "46999  310031           0\n",
              "\n",
              "[47000 rows x 2 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Using the model trained above to make predictions on the test data\n",
        "\n",
        "test_data_transformed = scaler.transform(test_data)\n",
        "test_data_preds = model.predict(test_data_transformed)\n",
        "cols = {'key':test_data['application_key'], 'prediction':test_data_preds};\n",
        "submission_df = pd.DataFrame(cols)\n",
        "submission_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPifoMWgYBwq"
      },
      "outputs": [],
      "source": [
        "submission_df.to_csv('Ida_group_20_9.csv', header=False, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Amex_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KUcM5E2MxNFX",
        "vFdoISZHhF7_",
        "Q0EedmerxNFc",
        "y2y-3Kt6xNFk",
        "fJarxNeQhg_L",
        "jlqCih3txNFo",
        "-mWO66QRxNFr",
        "cKiH4nUNnHDy",
        "eUN_UKhl2DXb",
        "tH-lSR_wgagO",
        "4qtlvqyIhHx8",
        "DGMC-GjO7lJe",
        "zRqf8tBQIchw",
        "XWGKRkLJInk8",
        "7C3aZVG5IyhV",
        "RI5oMHGwzVg9"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}